"""
test_complex_task.py
è¤‡é›‘ãªã‚¿ã‚¹ã‚¯: ã‚¨ãƒãƒ«ã‚®ãƒ¼ Ã— æ™‚é–“åˆ¶é™ Ã— å¥½ã¿ Ã— å±é™º

4ã¤ã®è¦ç´ ã§ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•
â†’ è¨€èªåŒ–ãŒè¤‡é›‘ã«ãªã‚‹
"""

from world import World
from hida import Hida
from qualia import QualiaLayer
from l5_sync import L5Sync, calculate_l2_activity, calculate_l3_activity, calculate_l4_activity
import subprocess
import json
import urllib.request
import urllib.error
import os


def ask_ollama(prompt, model="gemma3:4b"):
    """ollamaã«èã"""
    try:
        result = subprocess.run(
            ["ollama", "run", model, prompt],
            capture_output=True,
            text=True,
            timeout=60,
            encoding='utf-8',
            errors='replace'
        )
        if result.returncode == 0:
            return result.stdout.strip()
        return None
    except:
        return None


def ask_claude(prompt):
    """Claude APIã«èã"""
    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
    if not api_key:
        print("  (ANTHROPIC_API_KEYæœªè¨­å®š)")
        return None
    
    data = json.dumps({
        "model": "claude-sonnet-4-20250514",
        "max_tokens": 300,
        "messages": [{"role": "user", "content": prompt}]
    }).encode('utf-8')
    
    req = urllib.request.Request(
        "https://api.anthropic.com/v1/messages",
        data=data,
        headers={
            "Content-Type": "application/json",
            "x-api-key": api_key,
            "anthropic-version": "2023-06-01"
        }
    )
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            result = json.loads(response.read().decode('utf-8'))
            return result['content'][0]['text']
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        print(f"  (Claude APIã‚¨ãƒ©ãƒ¼: {e.code} {e.reason})")
        print(f"  (è©³ç´°: {error_body})")
        return None
    except Exception as e:
        print(f"  (Claude APIã‚¨ãƒ©ãƒ¼: {e})")
        return None


def ask_llm(prompt):
    """Claudeå„ªå…ˆã€ãªã‘ã‚Œã°ollama"""
    # ã¾ãšClaudeè©¦ã™
    result = ask_claude(prompt)
    if result:
        return result, "claude"
    # ãªã‘ã‚Œã°ollama
    result = ask_ollama(prompt)
    if result:
        return result, "ollama"
    return "(LLMæœªæ¥ç¶š)", "none"


def create_complex_world():
    """è¤‡é›‘ãªä¸–ç•Œ"""
    world = World(size=12)
    
    # å¤–å£
    for i in range(12):
        world.add_wall(i, 0)
        world.add_wall(i, 11)
        world.add_wall(0, i)
        world.add_wall(11, i)
    
    # å±é™ºã‚¾ãƒ¼ãƒ³ï¼ˆå³ä¸Šï¼‰
    for x in range(7, 10):
        for y in range(2, 5):
            world.add_danger(x, y)
    
    # ãƒœãƒ¼ãƒ«3ã¤ï¼ˆè·é›¢ã¨å±é™ºåº¦ãŒé•ã†ï¼‰
    world.add_object("ball", 8, 3, color="red")    # é ã„ + å±é™ºã‚¾ãƒ¼ãƒ³
    world.add_object("ball", 4, 4, color="blue")   # ä¸­é–“ + å®‰å…¨
    world.add_object("ball", 2, 6, color="green")  # è¿‘ã„ + å®‰å…¨
    
    # ã‚´ãƒ¼ãƒ«
    world.add_object("goal", 6, 9, color=None)
    
    # HIDAåˆæœŸä½ç½®ï¼ˆå·¦ä¸‹ï¼‰
    world.hida_pos = [2, 8]
    world.hida_dir = 'N'
    
    return world


class ComplexHida:
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨æ™‚é–“ã‚’æŒã¤HIDA"""
    
    def __init__(self, color_pref):
        self.hida = Hida()
        self.hida.l2 = QualiaLayer(color_preference=color_pref)
        
        # èº«ä½“çŠ¶æ…‹
        self.energy = 1.0
        self.fatigue = 0.0
        
        # æ™‚é–“
        self.deadline = 40
        self.step = 0
        
        # å±¥æ­´ï¼ˆè¨€èªåŒ–ç”¨ï¼‰
        self.history = []
    
    def get_urgency(self):
        """æ®‹ã‚Šæ™‚é–“ã‹ã‚‰urgencyã‚’è¨ˆç®—"""
        remaining = self.deadline - self.step
        if remaining <= 0:
            return 1.0
        return max(0, 1.0 - (remaining / self.deadline))
    
    def consume_energy(self, amount=0.02):
        """ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»"""
        self.energy = max(0, self.energy - amount)
        self.fatigue = min(1.0, self.fatigue + amount * 0.5)
    
    def update_qualia_from_body(self):
        """èº«ä½“çŠ¶æ…‹ â†’ ã‚¯ã‚ªãƒªã‚¢"""
        q = self.hida.l2.qualia
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½ã„ â†’ urgencyä¸Šæ˜‡
        if self.energy < 0.3:
            q['urgency'] = min(1.0, q.get('urgency', 0) + 0.3)
        
        # ç–²åŠ´ â†’ desireæ¸›å°‘
        if self.fatigue > 0.5:
            q['desire'] = max(0, q.get('desire', 0.5) - self.fatigue * 0.3)
        
        # æ™‚é–“ â†’ urgency
        q['urgency'] = max(q.get('urgency', 0), self.get_urgency())
    
    def calculate_scores(self, balls):
        """å„ãƒœãƒ¼ãƒ«ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        q = self.hida.l2.qualia
        scores = {}
        details = {}
        
        for color, info in balls.items():
            pos = info['pos']
            dist = info['dist']
            is_danger = info['is_danger']
            
            # å¥½ã¿
            pref_score = self.hida.l2.get_color_desire(color) * 10
            
            # è·é›¢ï¼ˆurgencyé«˜ã„ã¨é‡è¦ï¼‰
            urgency = q.get('urgency', 0)
            dist_penalty = -dist * (0.5 + urgency * 1.0)
            
            # å±é™ºï¼ˆfearé«˜ã„ã¨é‡è¦ï¼‰
            fear = q.get('fear', 0)
            danger_penalty = -10 * fear if is_danger else 0
            
            # ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆé ã„ã¨å³ã—ã„ï¼‰
            energy_penalty = 0
            if self.energy < 0.5 and dist > 5:
                energy_penalty = -5 * (1 - self.energy)
            
            total = pref_score + dist_penalty + danger_penalty + energy_penalty
            
            scores[color] = total
            details[color] = {
                'preference': pref_score,
                'distance_penalty': dist_penalty,
                'danger_penalty': danger_penalty,
                'energy_penalty': energy_penalty,
                'total': total,
                'dist': dist,
                'is_danger': is_danger
            }
        
        return scores, details
    
    def record_state(self, action, chosen=None, details=None):
        """çŠ¶æ…‹ã‚’å±¥æ­´ã«è¨˜éŒ²"""
        q = self.hida.l2.qualia
        self.history.append({
            'step': self.step,
            'action': action,
            'chosen': chosen,
            'energy': self.energy,
            'fatigue': self.fatigue,
            'urgency': q.get('urgency', 0),
            'fear': q.get('fear', 0),
            'desire': q.get('desire', 0),
            'details': details
        })


def run_complex_task(color_pref, initial_energy=1.0, deadline=40):
    """è¤‡é›‘ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
    
    world = create_complex_world()
    agent = ComplexHida(color_pref)
    agent.energy = initial_energy
    agent.deadline = deadline
    
    hida = agent.hida
    hida.pos = world.hida_pos.copy()
    hida.direction = world.hida_dir
    hida.seen_this_session = set()
    
    # ãƒœãƒ¼ãƒ«ã‚’ç™ºè¦‹æ¸ˆã¿ã«ã™ã‚‹
    hida.found_objects[(8, 3)] = {'name': 'ball', 'color': 'red'}
    hida.found_objects[(4, 4)] = {'name': 'ball', 'color': 'blue'}
    hida.found_objects[(2, 6)] = {'name': 'ball', 'color': 'green'}
    hida.found_objects[(6, 9)] = {'name': 'goal', 'color': None}
    
    # åœ°å›³
    for x in range(1, 11):
        for y in range(1, 11):
            if world.grid[y][x] == 'danger':
                hida.internal_map[(x, y)] = 'danger'
            else:
                hida.internal_map[(x, y)] = 'empty'
    
    print("=== è¤‡é›‘ã‚¿ã‚¹ã‚¯: ã‚¨ãƒãƒ«ã‚®ãƒ¼ Ã— æ™‚é–“ Ã— å¥½ã¿ Ã— å±é™º ===")
    print(f"åˆæœŸã‚¨ãƒãƒ«ã‚®ãƒ¼: {initial_energy}")
    print(f"åˆ¶é™æ™‚é–“: {deadline}ã‚¹ãƒ†ãƒƒãƒ—")
    print(f"è‰²å¥½ã¿: {color_pref}")
    print()
    world.display()
    print(f"  èµ¤: é ã„(dist=7) + å±é™ºã‚¾ãƒ¼ãƒ³")
    print(f"  é’: ä¸­é–“(dist=4) + å®‰å…¨")
    print(f"  ç·‘: è¿‘ã„(dist=2) + å®‰å…¨")
    
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    grabbed = None
    goal_reached = False
    
    for step in range(deadline + 10):
        agent.step = step
        
        # èº«ä½“çŠ¶æ…‹ â†’ ã‚¯ã‚ªãƒªã‚¢
        agent.update_qualia_from_body()
        q = hida.l2.qualia
        
        # ãƒœãƒ¼ãƒ«æƒ…å ±
        balls = {}
        for pos, obj in hida.found_objects.items():
            if obj.get('name') == 'ball':
                color = obj.get('color')
                dist = abs(pos[0] - hida.pos[0]) + abs(pos[1] - hida.pos[1])
                is_danger = hida.internal_map.get(pos) == 'danger'
                balls[color] = {'pos': pos, 'dist': dist, 'is_danger': is_danger}
        
        # ã‚´ãƒ¼ãƒ«æƒ…å ±
        goal_pos = None
        for pos, obj in hida.found_objects.items():
            if obj.get('name') == 'goal':
                goal_pos = pos
        
        # è¡Œå‹•æ±ºå®š
        if hida.holding and goal_pos:
            # ã‚´ãƒ¼ãƒ«ã¸
            target = goal_pos
            action = "go_to_goal"
        elif balls and not hida.holding:
            # ãƒœãƒ¼ãƒ«é¸æŠ
            scores, details = agent.calculate_scores(balls)
            chosen = max(scores, key=scores.get)
            target = balls[chosen]['pos']
            action = f"go_to_{chosen}"
            
            # é‡è¦ãªæ±ºå®šæ™‚ã®ã¿è¨˜éŒ²
            if step % 5 == 0 or step == 0:
                agent.record_state(action, chosen, details)
                print(f"\n  Step {step}: E={agent.energy:.2f} U={q.get('urgency', 0):.2f} F={q.get('fear', 0):.2f}")
                print(f"    ã‚¹ã‚³ã‚¢: ", end="")
                for c, s in scores.items():
                    marker = "â†’" if c == chosen else "  "
                    print(f"{marker}{c}={s:.1f} ", end="")
                print()
        else:
            target = None
            action = "wait"
        
        # ç§»å‹•
        if target:
            hx, hy = hida.pos
            tx, ty = target
            
            if hx != tx or hy != ty:
                # 1æ­©ç§»å‹•
                dx = 1 if tx > hx else (-1 if tx < hx else 0)
                dy = 1 if ty > hy else (-1 if ty < hy else 0)
                
                new_pos = [hx + dx, hy + dy]
                
                # å±é™ºã‚¾ãƒ¼ãƒ³ãªã‚‰fearä¸Šæ˜‡
                if hida.internal_map.get(tuple(new_pos)) == 'danger':
                    q['fear'] = min(1.0, q.get('fear', 0) + 0.15)
                else:
                    q['fear'] = max(0, q.get('fear', 0) - 0.05)
                
                hida.pos = new_pos
                agent.consume_energy(0.03)
            else:
                # åˆ°ç€
                if not hida.holding:
                    # ãƒœãƒ¼ãƒ«å–å¾—ãƒã‚§ãƒƒã‚¯
                    for color, info in balls.items():
                        if tuple(info['pos']) == tuple(target):
                            grabbed = color
                            hida.holding = {'color': color}
                            if tuple(target) in hida.found_objects:
                                del hida.found_objects[tuple(target)]
                            agent.record_state(f"grabbed_{color}", color, None)
                            print(f"\n  ğŸ‰ Step {step}: {color}ãƒœãƒ¼ãƒ«ã‚’å–ã£ãŸï¼")
                            break
                elif hida.holding and goal_pos and tuple(target) == tuple(goal_pos):
                    goal_reached = True
                    agent.record_state("goal_reached", grabbed, None)
                    print(f"\n  ğŸ† Step {step}: ã‚´ãƒ¼ãƒ«åˆ°é”ï¼")
                    break
        
        # æ™‚é–“åˆ‡ã‚Œ
        if step >= deadline:
            agent.record_state("timeout", None, None)
            print(f"\n  â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼")
            break
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ‡ã‚Œ
        if agent.energy <= 0:
            agent.record_state("exhausted", None, None)
            print(f"\n  ğŸ’€ ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ‡ã‚Œï¼")
            break
    
    # çµæœ
    print(f"\n=== çµæœ ===")
    print(f"  å–ã£ãŸãƒœãƒ¼ãƒ«: {grabbed}")
    print(f"  ã‚´ãƒ¼ãƒ«åˆ°é”: {goal_reached}")
    print(f"  æœ€çµ‚ã‚¨ãƒãƒ«ã‚®ãƒ¼: {agent.energy:.2f}")
    print(f"  æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—: {agent.step}")
    
    return agent, grabbed, goal_reached


def verbalize_journey(agent, grabbed, goal_reached):
    """æ—…ã®æŒ¯ã‚Šè¿”ã‚Šã‚’è¨€èªåŒ–"""
    
    # å±¥æ­´ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    history_text = ""
    for h in agent.history:
        history_text += f"Step {h['step']}: {h['action']}"
        if h['details']:
            for c, d in h['details'].items():
                history_text += f"\n  {c}: å¥½ã¿{d['preference']:.0f} è·é›¢{d['distance_penalty']:.1f} å±é™º{d['danger_penalty']:.1f} ä½“åŠ›{d['energy_penalty']:.1f} = {d['total']:.1f}"
        history_text += f"\n  çŠ¶æ…‹: E={h['energy']:.2f} U={h['urgency']:.2f} F={h['fear']:.2f}\n"
    
    prompt = f"""ã‚ãªãŸã¯HIDAã¨ã„ã†æ¢ç´¢ãƒ­ãƒœãƒƒãƒˆã§ã™ã€‚
ä»Šå›ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’æŒ¯ã‚Šè¿”ã£ã¦ã€1äººç§°ã§èªã£ã¦ãã ã•ã„ã€‚

ã€ã‚ãªãŸã®å¥½ã¿ã€‘
èµ¤ãŒå¤§å¥½ãï¼ˆ1.0ï¼‰ã€é’ã¯æ™®é€šï¼ˆ0.5ï¼‰ã€ç·‘ã¯è‹¦æ‰‹ï¼ˆ0.3ï¼‰

ã€ãƒœãƒ¼ãƒ«ã®é…ç½®ã€‘
- èµ¤ãƒœãƒ¼ãƒ«: é ãã¦å±é™ºã‚¾ãƒ¼ãƒ³ã«ã‚ã‚‹
- é’ãƒœãƒ¼ãƒ«: ä¸­é–“è·é›¢ã§å®‰å…¨
- ç·‘ãƒœãƒ¼ãƒ«: è¿‘ãã¦å®‰å…¨

ã€ä»Šå›ã®æ—…ã®è¨˜éŒ²ã€‘
{history_text}

ã€çµæœã€‘
å–ã£ãŸãƒœãƒ¼ãƒ«: {grabbed}
ã‚´ãƒ¼ãƒ«åˆ°é”: {goal_reached}
æœ€çµ‚ã‚¨ãƒãƒ«ã‚®ãƒ¼: {agent.energy:.2f}

ã“ã®æ—…ã‚’æŒ¯ã‚Šè¿”ã£ã¦ã€ä»¥ä¸‹ã‚’1äººç§°ã§èªã£ã¦ãã ã•ã„ï¼ˆ3-4æ–‡ã§ï¼‰ï¼š
- æœ€åˆä½•ã‚’æ€ã£ãŸã‹
- é€”ä¸­ã§ã©ã†æ„Ÿã˜ãŸã‹
- ãªãœãã®é¸æŠã‚’ã—ãŸã‹
- çµæœã«ã¤ã„ã¦ã©ã†æ€ã†ã‹

æ•°å€¤ã‚’ãã®ã¾ã¾è¨€ã†ã®ã§ã¯ãªãã€æ„Ÿè¦šã¨ã—ã¦è¡¨ç¾ã—ã¦ãã ã•ã„ï¼š"""

    print("\n=== æ—…ã®æŒ¯ã‚Šè¿”ã‚Š ===")
    response, llm = ask_llm(prompt)
    print(f"({llm})")
    print(f"ğŸ’­ {response}")


def main():
    # ãƒ†ã‚¹ãƒˆ1: é€šå¸¸æ¡ä»¶
    print("\n" + "=" * 60)
    print("ã€ãƒ†ã‚¹ãƒˆ1ã€‘é€šå¸¸æ¡ä»¶ï¼ˆèµ¤å¥½ãï¼‰")
    print("=" * 60)
    color_pref = {'red': 1.0, 'blue': 0.5, 'green': 0.3}
    agent, grabbed, goal = run_complex_task(color_pref, initial_energy=1.0, deadline=40)
    verbalize_journey(agent, grabbed, goal)
    
    # ãƒ†ã‚¹ãƒˆ2: ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ¶é™
    print("\n" + "=" * 60)
    print("ã€ãƒ†ã‚¹ãƒˆ2ã€‘ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ¶é™ï¼ˆèµ¤å¥½ãã ã‘ã©ä½“åŠ›å°‘ãªã„ï¼‰")
    print("=" * 60)
    agent, grabbed, goal = run_complex_task(color_pref, initial_energy=0.4, deadline=40)
    verbalize_journey(agent, grabbed, goal)
    
    # ãƒ†ã‚¹ãƒˆ3: æ™‚é–“åˆ¶é™
    print("\n" + "=" * 60)
    print("ã€ãƒ†ã‚¹ãƒˆ3ã€‘æ™‚é–“åˆ¶é™ï¼ˆèµ¤å¥½ãã ã‘ã©æ€¥ã„ã§ã‚‹ï¼‰")
    print("=" * 60)
    agent, grabbed, goal = run_complex_task(color_pref, initial_energy=1.0, deadline=15)
    verbalize_journey(agent, grabbed, goal)


if __name__ == "__main__":
    main()
