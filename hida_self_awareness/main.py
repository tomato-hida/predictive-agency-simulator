"""
main.py
AIã®è‡ªå·±èªè­˜å®Ÿè£… - ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—

é£›é¨¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ + AIè„³
"""

import time
import json
from simple_world import SimpleWorld
from hida_state import HidaState
from ai_brain import AIBrain


def setup_world():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚’æ§‹ç¯‰"""
    world = SimpleWorld(size=5)
    
    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆé…ç½®
    world.add_object("red_ball", 1, 1, {"color": "red", "size": "small"})
    world.add_object("blue_box", 3, 0, {"color": "blue", "size": "large"})
    world.add_object("goal", 4, 4, {"type": "destination"})
    
    return world


def run_simulation(goal, max_steps=20, use_ollama=False, ollama_model="gemma3:4b", verbose=True, observe_mode=False):
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
    
    # åˆæœŸåŒ–
    world = setup_world()
    state = HidaState()
    brain = AIBrain(use_ollama=use_ollama, ollama_model=ollama_model)
    
    # ç›®æ¨™è¨­å®š
    state.set_goal(goal)
    
    mode = "ollama" if use_ollama else "rule-based"
    print(f"\n{'='*50}")
    print(f"ç›®æ¨™: {goal}")
    print(f"ãƒ¢ãƒ¼ãƒ‰: {mode}")
    if use_ollama:
        print(f"ãƒ¢ãƒ‡ãƒ«: {ollama_model}")
    if observe_mode:
        print(f"ã€ä½œè©±è¦³å¯Ÿãƒ¢ãƒ¼ãƒ‰ã€‘é”æˆå¾Œã‚‚{max_steps}ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§ç¶™ç¶š")
    print(f"ã€NEWã€‘é£›é¨¨ãŒè¡Œå‹•æ±ºå®šã€LLMã¯èª¬æ˜ã®ã¿")
    print(f"{'='*50}")
    
    # åˆæœŸçŠ¶æ…‹
    world.display()
    state.update_from_world(world)
    
    history = []
    goal_achieved = False  # é”æˆãƒ•ãƒ©ã‚°
    
    for step in range(max_steps):
        print(f"\n--- Step {step + 1} ---")
        
        # ç¾åœ¨ã®çŠ¶æ…‹ã‚’AIã«æ¸¡ã™
        current_state = state.to_json()
        
        # AIãŒåˆ¤æ–­ï¼ˆworldã‚‚æ¸¡ã™ï¼‰
        decision = brain.decide_action(current_state, world)
        
        action = decision.get('action', 'wait')
        rule_reason = decision.get('rule_reason', '')
        reasoning = decision.get('reasoning', '')
        self_awareness = decision.get('self_awareness', '')
        
        if verbose:
            print(f"ã€é£›é¨¨ã€‘è¡Œå‹•: {action}")
            print(f"ã€é£›é¨¨ã€‘ãƒ«ãƒ¼ãƒ«: {rule_reason}")
            if use_ollama:
                if reasoning and reasoning != rule_reason:
                    print(f"ã€LLMã€‘èª¬æ˜: {reasoning}")
                if self_awareness:
                    print(f"ã€LLMã€‘è‡ªå·±èªè­˜: {self_awareness}")
            else:
                if self_awareness:
                    print(f"è‡ªå·±èªè­˜: {self_awareness}")
        
        # è¡Œå‹•ã‚’å®Ÿè¡Œ
        if action != 'wait':
            success, message = world.execute_primitive(action)
            print(f"å®Ÿè¡Œçµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'} - {message}")
        else:
            success, message = True, "waited"
            print("å¾…æ©Ÿ")
        
        # çŠ¶æ…‹æ›´æ–°
        state.update_from_world(world)
        state.update_after_action(action, success, message)
        
        # å±¥æ­´è¨˜éŒ²
        history.append({
            'step': step + 1,
            'action': action,
            'reasoning': reasoning,
            'self_awareness': self_awareness,
            'success': success,
            'conscious': state.L5_consciousness['is_conscious'],
            'sync_score': state.L5_consciousness['sync_score']
        })
        
        if verbose:
            world.display()
            state.summary()
        
        # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯ï¼ˆmessageã‚‚æ¸¡ã™ï¼‰
        if not goal_achieved and check_goal_achieved(goal, world, state, message):
            goal_achieved = True
            print(f"\nğŸ‰ ç›®æ¨™é”æˆï¼ Step {step + 1}")
            if not observe_mode:
                break
            else:
                print("ã€ä½œè©±è¦³å¯Ÿãƒ¢ãƒ¼ãƒ‰ã€‘é”æˆå¾Œã®ä½œè©±ã‚’è¦³å¯Ÿä¸­...")
            
        time.sleep(0.5)  # è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ã®é…å»¶
    
    return history


def check_goal_achieved(goal, world, state, last_message=""):
    """ç›®æ¨™é”æˆã‚’ãƒã‚§ãƒƒã‚¯"""
    goal_lower = goal.lower()
    
    # Bæ¡ˆ: release at goal! ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§åˆ¤å®š
    if "at goal!" in last_message:
        return True
    
    # ã€Œã€œã‚’å±Šã‘ã‚‹ã€ç³»ï¼ˆå…ˆã«åˆ¤å®š - å±Šã‘ã‚‹ã«ã¯æ´ã‚€ã ã‘ã˜ã‚ƒãƒ€ãƒ¡ï¼‰
    if "å±Šã‘" in goal or "deliver" in goal_lower or "goal" in goal_lower:
        # ã‚´ãƒ¼ãƒ«ã®ä½ç½®ã‚’å–å¾—
        goal_pos = None
        for name, obj in world.objects.items():
            if name == 'goal':
                goal_pos = obj['pos']
                break
        if goal_pos:
            # ã‚´ãƒ¼ãƒ«ã®éš£ã«ã„ã‚‹ã‹
            hx, hy = world.hida_pos
            gx, gy = goal_pos
            if abs(hx - gx) <= 1 and abs(hy - gy) <= 1:
                # ã‚´ãƒ¼ãƒ«ã®ä½ç½®ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã‚ã‚‹ã‹ï¼ˆç½®ã„ãŸï¼‰
                if world.grid[gy][gx] and world.grid[gy][gx] != 'goal':
                    return True
        return False  # å±Šã‘ã‚‹ã‚¿ã‚¹ã‚¯ã¯é€”ä¸­ã§çµ‚ã‚ã‚‰ãªã„
    
    # ã€Œã€œã‚’è¦‹ã¤ã‘ã‚‹/æ´ã‚€ã€ç³»ï¼ˆå±Šã‘ã‚‹ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
    if "è¦‹ã¤ã‘" in goal or "find" in goal_lower or "æ´" in goal:
        if "red" in goal_lower and state.L1_body['holding'] == 'red_ball':
            return True
        if "blue" in goal_lower and state.L1_body['holding'] == 'blue_box':
            return True
    
    return False


def analyze_history(history):
    """å±¥æ­´ã‚’åˆ†æ"""
    print("\n" + "="*50)
    print("å®Ÿè¡Œåˆ†æ")
    print("="*50)
    
    total = len(history)
    conscious_count = sum(1 for h in history if h['conscious'])
    success_count = sum(1 for h in history if h['success'])
    avg_sync = sum(h['sync_score'] for h in history) / total if total > 0 else 0
    
    print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—: {total}")
    print(f"æ„è­˜ONç‡: {conscious_count}/{total} ({conscious_count/total*100:.1f}%)")
    print(f"è¡Œå‹•æˆåŠŸç‡: {success_count}/{total} ({success_count/total*100:.1f}%)")
    print(f"å¹³å‡åŒæœŸã‚¹ã‚³ã‚¢: {avg_sync:.2f}")
    
    print("\nè‡ªå·±èªè­˜ã®å¤‰åŒ–:")
    for i, h in enumerate(history):
        if i == 0 or h['self_awareness'] != history[i-1]['self_awareness']:
            print(f"  Step {h['step']}: {h['self_awareness']}")


if __name__ == "__main__":
    import sys
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ
    # python main.py                      â†’ ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆLLMä¸ä½¿ç”¨ï¼‰
    # python main.py ollama               â†’ ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ + ollamaèª¬æ˜
    # python main.py ollama gemma3:4b     â†’ ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
    # python main.py ollama gemma3:4b observe â†’ ä½œè©±è¦³å¯Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆé”æˆå¾Œã‚‚ç¶™ç¶šï¼‰
    
    use_ollama = False
    ollama_model = "gemma3:4b"
    observe_mode = False
    
    if len(sys.argv) > 1 and sys.argv[1] == "ollama":
        use_ollama = True
        if len(sys.argv) > 2:
            ollama_model = sys.argv[2]
        if len(sys.argv) > 3 and sys.argv[3] == "observe":
            observe_mode = True
    
    print("=== AIã®è‡ªå·±èªè­˜å®Ÿè£…ãƒ†ã‚¹ãƒˆï¼ˆé£›é¨¨ã‚¢ãƒ¼ã‚­æº–æ‹ ç‰ˆï¼‰ ===")
    print("ã€å¤‰æ›´ç‚¹ã€‘é£›é¨¨ãŒè¡Œå‹•æ±ºå®šã€LLMã¯èª¬æ˜ã®ã¿")
    if observe_mode:
        print("ã€ä½œè©±è¦³å¯Ÿãƒ¢ãƒ¼ãƒ‰ã€‘ç›®æ¨™é”æˆå¾Œã‚‚ç¶™ç¶šã—ã¦ä½œè©±ã‚’è¦³å¯Ÿ")
    
    history = run_simulation(
        goal="red ballã‚’è¦‹ã¤ã‘ã¦goalã«å±Šã‘ã‚‹",
        max_steps=30,
        use_ollama=use_ollama,
        ollama_model=ollama_model,
        verbose=True,
        observe_mode=observe_mode
    )
    
    analyze_history(history)
    
    print("\n" + "="*50)
    print("å®Ÿè¡Œæ–¹æ³•:")
    print("  python main.py                       â†’ ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹")
    print("  python main.py ollama                â†’ ãƒ«ãƒ¼ãƒ« + ollamaèª¬æ˜")
    print("  python main.py ollama gemma3:4b      â†’ ãƒ¢ãƒ‡ãƒ«æŒ‡å®š")
    print("  python main.py ollama gemma3:4b observe â†’ ä½œè©±è¦³å¯Ÿãƒ¢ãƒ¼ãƒ‰")
    print("="*50)
