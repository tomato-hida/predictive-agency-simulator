"""
hida_unified.py
HIDAçµ±åˆç‰ˆ - 5å±¤æ„è­˜ãƒ¢ãƒ‡ãƒ« + LLMè¨€èªåŒ–

L1: èº«ä½“å±¤ï¼ˆãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
L2: ã‚¯ã‚ªãƒªã‚¢å±¤ï¼ˆvalence/arousal + å€‹åˆ¥æ„Ÿæƒ…ï¼‰
L3: äºˆæ¸¬ãƒ»æ§‹é€ åŒ–å±¤ï¼ˆäºˆæ¸¬èª¤å·®ï¼‰
L4: è¨˜æ†¶å±¤ï¼ˆå†…éƒ¨ãƒãƒƒãƒ—ã€ç™ºè¦‹ç‰©ã€ãƒ©ãƒ™ãƒ«è¾æ›¸ï¼‰
L5: æ„è­˜å±¤ï¼ˆè‡ªèªã€è¨€èªåŒ–ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
"""

import math
import random
import subprocess
import json
import urllib.request
import urllib.error
import os
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple
from enum import Enum


# ==========================================
# L1: èº«ä½“å±¤
# ==========================================

class L1Body:
    """èº«ä½“ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ç®¡ç†"""
    
    def __init__(self):
        # ä½ç½®ãƒ»æ–¹å‘
        self.position = [0, 0]
        self.direction = 'N'  # N, E, S, W
        
        # èº«ä½“çŠ¶æ…‹
        self.energy = 1.0
        self.fatigue = 0.0
        self.damage = 0.0
        
        # æ‰€æŒ
        self.holding = None
        
        # æ„Ÿè¦šãƒãƒƒãƒ•ã‚¡ï¼ˆæœ€æ–°ã®çŸ¥è¦šï¼‰
        self.sense_buffer = {}
    
    def move_forward(self, world) -> bool:
        """å‰é€²"""
        dx, dy = {'N': (0, -1), 'S': (0, 1), 'E': (1, 0), 'W': (-1, 0)}[self.direction]
        new_pos = [self.position[0] + dx, self.position[1] + dy]
        
        # å£ãƒã‚§ãƒƒã‚¯
        if world.get_cell(new_pos[0], new_pos[1]) == 'wall':
            return False
        
        self.position = new_pos
        self._consume_energy(0.02)
        return True
    
    def turn_left(self):
        """å·¦å›è»¢"""
        dirs = ['N', 'W', 'S', 'E']
        self.direction = dirs[(dirs.index(self.direction) + 1) % 4]
        self._consume_energy(0.005)
    
    def turn_right(self):
        """å³å›è»¢"""
        dirs = ['N', 'E', 'S', 'W']
        self.direction = dirs[(dirs.index(self.direction) + 1) % 4]
        self._consume_energy(0.005)
    
    def grab(self, obj):
        """æ´ã‚€"""
        self.holding = obj
        self._consume_energy(0.01)
    
    def release(self):
        """é›¢ã™"""
        released = self.holding
        self.holding = None
        self._consume_energy(0.01)
        return released
    
    def look(self, world) -> Dict:
        """å‘¨å›²ã‚’è¦‹ã‚‹ï¼ˆæ„Ÿè¦šå…¥åŠ›ï¼‰"""
        visible = {}
        x, y = self.position
        
        # å‘¨å›²8æ–¹å‘ + å‰æ–¹3ãƒã‚¹
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                nx, ny = x + dx, y + dy
                cell = world.get_cell(nx, ny)
                obj = world.get_object(nx, ny)
                visible[(nx, ny)] = {'cell': cell, 'object': obj}
        
        # å‰æ–¹ã‚’é ãã¾ã§è¦‹ã‚‹
        fdx, fdy = {'N': (0, -1), 'S': (0, 1), 'E': (1, 0), 'W': (-1, 0)}[self.direction]
        for dist in range(1, 5):
            fx, fy = x + fdx * dist, y + fdy * dist
            cell = world.get_cell(fx, fy)
            if cell == 'wall':
                break
            obj = world.get_object(fx, fy)
            visible[(fx, fy)] = {'cell': cell, 'object': obj}
        
        self.sense_buffer = visible
        self._consume_energy(0.005)
        return visible
    
    def _consume_energy(self, amount: float):
        """ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»"""
        self.energy = max(0, self.energy - amount)
        self.fatigue = min(1.0, self.fatigue + amount * 0.3)
    
    def rest(self):
        """ä¼‘æ†©ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼å›å¾©ï¼‰"""
        self.energy = min(1.0, self.energy + 0.05)
        self.fatigue = max(0, self.fatigue - 0.03)
    
    def get_state(self) -> Dict:
        return {
            'position': self.position.copy(),
            'direction': self.direction,
            'energy': self.energy,
            'fatigue': self.fatigue,
            'damage': self.damage,
            'holding': self.holding
        }


# ==========================================
# L2: ã‚¯ã‚ªãƒªã‚¢å±¤
# ==========================================

class L2Qualia:
    """ã‚¯ã‚ªãƒªã‚¢ï¼ˆæ„Ÿæƒ…çš„è©•ä¾¡ï¼‰"""
    
    def __init__(self, color_preference=None):
        # åŸºæœ¬2è»¸ï¼ˆRussellå††ç’°ãƒ¢ãƒ‡ãƒ«ï¼‰
        self.valence = 0.0   # å¿«-ä¸å¿« (-1 to 1)
        self.arousal = 0.0   # è¦šé†’-æ²ˆé™ (-1 to 1)
        
        # å€‹åˆ¥ã‚¯ã‚ªãƒªã‚¢ï¼ˆåŸºæœ¬è»¸ã‹ã‚‰æ´¾ç”Ÿ or ç›´æ¥è¨­å®šï¼‰
        self.qualia = {
            'fear': 0.0,       # ææ€–
            'desire': 0.0,     # æ¬²æ±‚
            'surprise': 0.0,   # é©šã
            'curiosity': 0.5,  # å¥½å¥‡å¿ƒ
            'urgency': 0.0,    # ç·Šæ€¥åº¦
            'anger': 0.0,      # æ€’ã‚Šï¼ˆæ–°è¦ï¼‰
            'sadness': 0.0,    # æ‚²ã—ã¿ï¼ˆæ–°è¦ï¼‰
            'joy': 0.0,        # å–œã³ï¼ˆæ–°è¦ï¼‰
            'disgust': 0.0,    # å«Œæ‚ªï¼ˆæ–°è¦ï¼‰
        }
        
        # æ¸›è¡°ç‡
        self.decay = {
            'fear': 0.9,
            'desire': 0.95,
            'surprise': 0.7,
            'curiosity': 0.98,
            'urgency': 0.95,
            'anger': 0.85,     # æ€’ã‚Šã¯æ¯”è¼ƒçš„æ—©ãåã¾ã‚‹
            'sadness': 0.92,   # æ‚²ã—ã¿ã¯ã‚†ã£ãã‚Šæ¶ˆãˆã‚‹
            'joy': 0.9,        # å–œã³ã‚‚æ¯”è¼ƒçš„æ—©ãæ¶ˆãˆã‚‹
            'disgust': 0.8,    # å«Œæ‚ªã¯æ—©ãæ¶ˆãˆã‚‹
        }
        
        # è‰²ã®å¥½ã¿ï¼ˆDNAç”±æ¥ï¼‰
        self.color_preference = color_preference or {
            'red': 0.5, 'blue': 0.5, 'yellow': 0.5, 'green': 0.5
        }
        
        # å¤‰èª¿å€¤ï¼ˆçµŒé¨“ã‹ã‚‰ï¼‰
        self.modulation = {
            'fear_weight': 1.0,
            'safe_preference': 0.0,
            'energy_caution': 0.0
        }
    
    def apply_modulation(self, mod: Dict):
        """å¤‰èª¿å€¤ã‚’é©ç”¨"""
        self.modulation = mod.copy()
    
    def update_from_body(self, l1_state: Dict):
        """L1èº«ä½“çŠ¶æ…‹ã‹ã‚‰ã‚¯ã‚ªãƒªã‚¢æ›´æ–°"""
        energy = l1_state['energy']
        fatigue = l1_state['fatigue']
        damage = l1_state['damage']
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½ä¸‹ â†’ ä¸å¿« + æ²ˆé™ + urgency
        if energy < 0.3:
            self.valence -= 0.1
            self.arousal -= 0.05
            self.qualia['urgency'] = min(1.0, self.qualia['urgency'] + 0.2)
        
        # ç–²åŠ´ â†’ ä¸å¿« + æ²ˆé™
        if fatigue > 0.5:
            self.valence -= 0.05 * fatigue
            self.arousal -= 0.05 * fatigue
        
        # ãƒ€ãƒ¡ãƒ¼ã‚¸ â†’ fear + ä¸å¿«
        if damage > 0:
            self.qualia['fear'] = min(1.0, self.qualia['fear'] + damage * 0.5)
            self.valence -= damage * 0.3
        
        # ç¯„å›²åˆ¶é™
        self.valence = max(-1, min(1, self.valence))
        self.arousal = max(-1, min(1, self.arousal))
    
    def update_from_prediction_error(self, errors: List[Dict]):
        """L3äºˆæ¸¬èª¤å·®ã‹ã‚‰ã‚¯ã‚ªãƒªã‚¢æ›´æ–°"""
        for error in errors:
            error_type = error.get('type', '')
            magnitude = error.get('magnitude', 0.5)
            
            if error_type == 'new_object':
                self.qualia['surprise'] = min(1.0, self.qualia['surprise'] + magnitude * 0.5)
                self.qualia['curiosity'] = min(1.0, self.qualia['curiosity'] + magnitude * 0.3)
                self.arousal += magnitude * 0.2
            
            if error_type == 'danger':
                self.qualia['fear'] = min(1.0, self.qualia['fear'] + magnitude * 0.3)
                self.valence -= magnitude * 0.2
                self.arousal += magnitude * 0.3
            
            if error_type == 'goal_found':
                self.qualia['desire'] = min(1.0, self.qualia['desire'] + magnitude * 0.5)
                self.valence += magnitude * 0.3
        
        self.valence = max(-1, min(1, self.valence))
        self.arousal = max(-1, min(1, self.arousal))
    
    def update_in_danger_zone(self, in_danger: bool):
        """å±é™ºã‚¾ãƒ¼ãƒ³å†…ã§ã®æ›´æ–°"""
        if in_danger:
            self.qualia['fear'] = min(1.0, self.qualia['fear'] + 0.15)
            self.arousal = min(1.0, self.arousal + 0.1)
        else:
            self.qualia['fear'] = max(0, self.qualia['fear'] - 0.05)
    
    def decay_qualia(self):
        """ã‚¯ã‚ªãƒªã‚¢ã®è‡ªç„¶æ¸›è¡°"""
        for key in self.qualia:
            self.qualia[key] *= self.decay.get(key, 0.95)
        
        # åŸºæœ¬è»¸ã‚‚ä¸­å¤®ã«æˆ»ã‚‹
        self.valence *= 0.98
        self.arousal *= 0.95
    
    def get_color_desire(self, color: str) -> float:
        """è‰²ã¸ã®æ¬²æ±‚åº¦"""
        return self.color_preference.get(color, 0.5)
    
    def get_state(self) -> Dict:
        return {
            'valence': self.valence,
            'arousal': self.arousal,
            'qualia': self.qualia.copy(),
            'color_preference': self.color_preference.copy()
        }


# ==========================================
# L3: äºˆæ¸¬ãƒ»æ§‹é€ åŒ–å±¤
# ==========================================

class L3Prediction:
    """äºˆæ¸¬ã¨èª¤å·®æ¤œå‡º"""
    
    def __init__(self):
        self.predictions = {}  # äºˆæ¸¬ã—ãŸå†…å®¹
        self.errors = []       # ä»Šã‚¹ãƒ†ãƒƒãƒ—ã®äºˆæ¸¬èª¤å·®
    
    def predict(self, l4_memory) -> Dict:
        """L4è¨˜æ†¶ã«åŸºã¥ã„ã¦äºˆæ¸¬"""
        # æ—¢çŸ¥ã®ãƒãƒƒãƒ—ã‹ã‚‰æ¬¡ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚’äºˆæ¸¬
        self.predictions = l4_memory.internal_map.copy()
        return self.predictions
    
    def compare_with_reality(self, sense_data: Dict, l4_memory) -> List[Dict]:
        """æ„Ÿè¦šãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬ã‚’æ¯”è¼ƒã€èª¤å·®ã‚’æ¤œå‡º"""
        self.errors = []
        
        for pos, data in sense_data.items():
            predicted = self.predictions.get(pos, 'unknown')
            actual_cell = data['cell']
            actual_obj = data['object']
            
            # æ–°ã—ã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç™ºè¦‹
            if actual_obj and pos not in l4_memory.found_objects:
                error = {
                    'type': 'new_object',
                    'pos': pos,
                    'object': actual_obj,
                    'magnitude': 0.8
                }
                
                # å±é™ºã‚¾ãƒ¼ãƒ³å†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                if actual_cell == 'danger':
                    error['type'] = 'danger'
                    error['magnitude'] = 1.0
                
                # ã‚´ãƒ¼ãƒ«ç™ºè¦‹
                if actual_obj.get('name') == 'goal':
                    error['type'] = 'goal_found'
                
                self.errors.append(error)
            
            # æœªçŸ¥ã®ã‚»ãƒ«ã‚’ç™ºè¦‹
            if predicted == 'unknown' and actual_cell != 'unknown':
                if actual_cell == 'danger':
                    self.errors.append({
                        'type': 'danger',
                        'pos': pos,
                        'magnitude': 0.6
                    })
        
        return self.errors
    
    def get_state(self) -> Dict:
        return {
            'predictions_count': len(self.predictions),
            'errors': self.errors.copy()
        }


# ==========================================
# L4: è¨˜æ†¶å±¤
# ==========================================

class L4Memory:
    """è¨˜æ†¶ï¼ˆå†…éƒ¨ãƒãƒƒãƒ—ã€ç™ºè¦‹ç‰©ã€ãƒ©ãƒ™ãƒ«è¾æ›¸ã€é•·æœŸè¨˜æ†¶ï¼‰"""
    
    LTM_FILE = "hida_ltm.json"
    
    def __init__(self):
        self.internal_map = {}      # (x,y) -> cell_type
        self.found_objects = {}     # (x,y) -> object_info
        self.visited = set()        # è¨ªã‚ŒãŸå ´æ‰€
        
        # çŸ­æœŸè¨˜æ†¶ï¼ˆä»Šå›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰
        self.stm = []
        
        # é•·æœŸè¨˜æ†¶ï¼ˆæ°¸ç¶šåŒ–ï¼‰
        self.ltm = self._load_ltm()
        
        # æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«è¾æ›¸ï¼ˆL2ã®æ•°å€¤ â†’ è¨€è‘‰ï¼‰
        self.emotion_labels = {
            'ãƒ¯ã‚¯ãƒ¯ã‚¯': {'valence': (0.3, 1.0), 'arousal': (0.5, 1.0)},
            'ãƒªãƒ©ãƒƒã‚¯ã‚¹': {'valence': (0.2, 1.0), 'arousal': (-1.0, -0.3)},
            'ã‚¤ãƒ©ã‚¤ãƒ©': {'valence': (-1.0, -0.3), 'arousal': (0.3, 1.0)},
            'ã¸ã¨ã¸ã¨': {'valence': (-0.5, 0.0), 'arousal': (-1.0, -0.5)},
            'æ€–ã„': {'fear': (0.5, 1.0)},
            'æ¬²ã—ã„': {'desire': (0.6, 1.0)},
            'é©šã„ãŸ': {'surprise': (0.5, 1.0)},
            'æ€¥ãŒãªãã‚ƒ': {'urgency': (0.6, 1.0)},
        }
        
        # çµŒé¨“ã‹ã‚‰å­¦ã‚“ã å‚¾å‘ï¼ˆé•·æœŸè¨˜æ†¶ã‹ã‚‰æ§‹ç¯‰ï¼‰
        self.learned_tendencies = self._build_tendencies()
        
        # å¤‰èª¿å€¤ï¼ˆæ•°å€¤ã®ã¿ã€ãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰
        self.modulation = self._load_modulation()
        self._update_modulation()
    
    def _load_modulation(self) -> Dict:
        """å¤‰èª¿å€¤ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
        try:
            with open("hida_modulation.json", 'r', encoding='utf-8') as f:
                mod = json.load(f)
                print(f"  [Mod] å¤‰èª¿å€¤ã‚’èª­ã¿è¾¼ã¿: fear={mod.get('fear_weight', 1.0):.2f}, safe={mod.get('safe_preference', 0.0):.2f}")
                return mod
        except FileNotFoundError:
            return {
                'fear_weight': 1.0,      # ææ€–æ„Ÿåº¦ï¼ˆ1.0=æ¨™æº–ï¼‰
                'safe_preference': 0.0,  # å®‰å…¨å¿—å‘ï¼ˆ0.0=ãªã—ï¼‰
                'energy_caution': 0.0,   # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ…é‡ã•
                'experience_count': 0    # çµŒé¨“å›æ•°
            }
        except:
            return {'fear_weight': 1.0, 'safe_preference': 0.0, 'energy_caution': 0.0, 'experience_count': 0}
    
    def _save_modulation(self):
        """å¤‰èª¿å€¤ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open("hida_modulation.json", 'w', encoding='utf-8') as f:
                json.dump(self.modulation, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"  [Mod] ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_modulation(self):
        """çµŒé¨“ã‹ã‚‰å¤‰èª¿å€¤ã‚’æ›´æ–°ï¼ˆæ•°å€¤ã®ã¿ï¼‰"""
        t = self.learned_tendencies
        old_mod = self.modulation.copy()
        
        # çµŒé¨“å›æ•°
        self.modulation['experience_count'] = t['total_sessions']
        
        # å®‰å…¨å¿—å‘: çµŒé¨“ãŒã‚ã‚‹å ´åˆã¯è¨ˆç®—ã€ãªã„å ´åˆã¯0
        total_success = t['success_with_safe'] + t['success_with_red']
        if total_success > 0:
            safe_ratio = t['success_with_safe'] / total_success
            self.modulation['safe_preference'] = safe_ratio * 0.3  # æœ€å¤§0.3
        else:
            self.modulation['safe_preference'] = 0.0  # çµŒé¨“ãªã—ãªã‚‰0
        
        # å±é™ºçµŒé¨“ â†’ fearæ„Ÿåº¦ãŒä¸ŠãŒã‚‹
        if t['danger_encounters'] > 0:
            self.modulation['fear_weight'] = 1.0 + (t['danger_encounters'] * 0.1)  # çµŒé¨“ã”ã¨ã«+0.1
        
        # å¿˜å´: fear_weightãŒå¾ã€…ã«ä¸‹ãŒã‚‹ï¼ˆæœ€ä½1.0ã¾ã§ï¼‰
        if self.modulation['fear_weight'] > 1.0:
            self.modulation['fear_weight'] *= 0.95  # æ¯ã‚»ãƒƒã‚·ãƒ§ãƒ³5%æ¸›è¡°
            if self.modulation['fear_weight'] < 1.0:
                self.modulation['fear_weight'] = 1.0
        
        # å¿˜å´: safe_preferenceã‚‚å¾ã€…ã«ä¸‹ãŒã‚‹ï¼ˆæœ€ä½0.0ã¾ã§ï¼‰
        if self.modulation['safe_preference'] > 0.0:
            self.modulation['safe_preference'] *= 0.98  # æ¯ã‚»ãƒƒã‚·ãƒ§ãƒ³2%æ¸›è¡°
            if self.modulation['safe_preference'] < 0.01:
                self.modulation['safe_preference'] = 0.0
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ‡ã‚ŒçµŒé¨“ â†’ ã‚¨ãƒãƒ«ã‚®ãƒ¼æ…é‡ã•ãŒä¸ŠãŒã‚‹
        if t['avg_final_energy'] < 0.3:
            self.modulation['energy_caution'] = (0.3 - t['avg_final_energy']) * 2  # æœ€å¤§0.6
        
        # å¤‰åŒ–ãŒã‚ã‚Œã°ä¿å­˜
        if self.modulation != old_mod:
            self._save_modulation()
            print(f"  [Mod] å¤‰èª¿å€¤æ›´æ–°: fear={self.modulation['fear_weight']:.2f}, safe={self.modulation['safe_preference']:.2f}")
    
    def get_modulation(self) -> Dict:
        """å¤‰èª¿å€¤ã‚’è¿”ã™"""
        return self.modulation.copy()
    
    def _load_ltm(self) -> List[Dict]:
        """é•·æœŸè¨˜æ†¶ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.LTM_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"  [LTM] {len(data)}ä»¶ã®è¨˜æ†¶ã‚’èª­ã¿è¾¼ã¿")
                return data
        except FileNotFoundError:
            print(f"  [LTM] æ–°è¦ï¼ˆè¨˜æ†¶ãªã—ï¼‰")
            return []
        except Exception as e:
            print(f"  [LTM] èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _save_ltm(self):
        """é•·æœŸè¨˜æ†¶ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open(self.LTM_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.ltm, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"  [LTM] ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _build_tendencies(self) -> Dict:
        """é•·æœŸè¨˜æ†¶ã‹ã‚‰å‚¾å‘ã‚’æ§‹ç¯‰"""
        tendencies = {
            'danger_pain': 0,          # ç—›ã„çµŒé¨“ã®å›æ•°
            'danger_fatigue': 0,       # ç–²åŠ´çµŒé¨“ã®å›æ•°
            'danger_encounters': 0,    # å±é™ºã«é­é‡ã—ãŸå›æ•°ï¼ˆäº’æ›ç”¨ï¼‰
            'danger_fear_total': 0.0,  # å±é™ºæ™‚ã®fearåˆè¨ˆ
            'success_with_red': 0,     # èµ¤ã§æˆåŠŸã—ãŸå›æ•°
            'success_with_safe': 0,    # å®‰å…¨è‰²ã§æˆåŠŸã—ãŸå›æ•°
            'total_sessions': 0,       # ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°
            'avg_final_energy': 0.5,   # å¹³å‡æœ€çµ‚ã‚¨ãƒãƒ«ã‚®ãƒ¼
        }
        
        if not self.ltm:
            return tendencies
        
        for memory in self.ltm:
            event = memory.get('event', '')
            qualia = memory.get('qualia', {})
            
            # ç—›ã¿çµŒé¨“
            if 'danger_pain' in event:
                tendencies['danger_pain'] += 1
                tendencies['danger_encounters'] += 1
                tendencies['danger_fear_total'] += qualia.get('fear', 0)
            
            # ç–²åŠ´çµŒé¨“
            if 'danger_fatigue' in event:
                tendencies['danger_fatigue'] += 1
            
            # goal_reached_with_XXX ã‚’è§£æ
            if 'goal_reached_with_red' in event:
                tendencies['success_with_red'] += 1
            elif 'goal_reached_with_green' in event or 'goal_reached_with_blue' in event:
                tendencies['success_with_safe'] += 1
            
            if memory.get('is_session_end'):
                tendencies['total_sessions'] += 1
                energy = memory.get('energy', 0.5)
                # ç§»å‹•å¹³å‡
                tendencies['avg_final_energy'] = (
                    tendencies['avg_final_energy'] * 0.7 + 
                    energy * 0.3
                )
        
        return tendencies
    
    def remember_consciously(self, event: str, l1_state: Dict, l2_state: Dict, 
                             is_session_end: bool = False):
        """æ„è­˜çš„ã«è¨˜æ†¶ã™ã‚‹ï¼ˆL5ãŒONã®æ™‚ã ã‘å‘¼ã°ã‚Œã‚‹ï¼‰"""
        memory = {
            'timestamp': self._get_timestamp(),
            'event': event,
            'position': l1_state.get('position'),
            'energy': l1_state.get('energy'),
            'qualia': {
                'fear': l2_state.get('qualia', {}).get('fear', 0),
                'desire': l2_state.get('qualia', {}).get('desire', 0),
                'urgency': l2_state.get('qualia', {}).get('urgency', 0),
                'valence': l2_state.get('valence', 0),
                'arousal': l2_state.get('arousal', 0),
            },
            'emotion_label': self.get_emotion_label(l2_state),
            'is_session_end': is_session_end
        }
        
        # çŸ­æœŸè¨˜æ†¶ã«è¿½åŠ 
        self.stm.append(memory)
        
        # é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã¯é•·æœŸè¨˜æ†¶ã«ã‚‚
        if self._is_significant(event, memory):
            self.ltm.append(memory)
            self._save_ltm()
            print(f"  [LTM] è¨˜æ†¶ä¿å­˜: {event}")
    
    def _is_significant(self, event: str, memory: Dict) -> bool:
        """é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã‹ã©ã†ã‹"""
        # é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆ
        significant_events = ['grabbed', 'goal_reached', 'danger', 'exhausted', 'timeout']
        if any(e in event for e in significant_events):
            return True
        
        # å¼·ã„æ„Ÿæƒ…
        qualia = memory.get('qualia', {})
        if qualia.get('fear', 0) > 0.5:
            return True
        if qualia.get('urgency', 0) > 0.7:
            return True
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        if memory.get('is_session_end'):
            return True
        
        return False
    
    def _get_timestamp(self) -> str:
        import datetime
        return datetime.datetime.now().isoformat()
    
    def get_fear_modifier(self) -> float:
        """éå»ã®çµŒé¨“ã‹ã‚‰fearä¿®æ­£å€¤ã‚’è¿”ã™"""
        if self.learned_tendencies['danger_encounters'] == 0:
            return 0.0
        
        # å±é™ºçµŒé¨“ãŒå¤šã„ã»ã©fearãŒä¸ŠãŒã‚Šã‚„ã™ã„
        avg_fear = (self.learned_tendencies['danger_fear_total'] / 
                   self.learned_tendencies['danger_encounters'])
        return avg_fear * 0.2  # 20%ã®å½±éŸ¿
    
    def get_personality_description(self) -> str:
        """æ€§æ ¼ã®èª¬æ˜ã‚’è¿”ã™"""
        t = self.learned_tendencies
        
        if t['total_sessions'] == 0:
            return "ã¾ã çµŒé¨“ãŒå°‘ãªã„æ–°äºº"
        
        descriptions = []
        
        # å±é™ºã¸ã®æ…‹åº¦
        if t['danger_encounters'] > 3 and t['danger_fear_total'] > 2:
            descriptions.append("æ…é‡æ´¾")
        elif t['success_with_red'] > t['success_with_safe']:
            descriptions.append("å†’é™ºå¥½ã")
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ç®¡ç†
        if t['avg_final_energy'] > 0.5:
            descriptions.append("ä½™è£•ã‚’æŒã£ã¦è¡Œå‹•")
        elif t['avg_final_energy'] < 0.2:
            descriptions.append("é™ç•Œã¾ã§é ‘å¼µã‚‹")
        
        return "ã€".join(descriptions) if descriptions else "ãƒãƒ©ãƒ³ã‚¹å‹"
    
    def update_from_sense(self, sense_data: Dict):
        """æ„Ÿè¦šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨˜æ†¶æ›´æ–°"""
        for pos, data in sense_data.items():
            self.internal_map[pos] = data['cell']
            if data['object']:
                self.found_objects[pos] = data['object']
    
    def update_from_errors(self, errors: List[Dict], qualia_intensity: float):
        """äºˆæ¸¬èª¤å·®ã‹ã‚‰è¨˜æ†¶æ›´æ–°ï¼ˆã‚¯ã‚ªãƒªã‚¢å¼·åº¦ã§é‡ã¿ä»˜ã‘ï¼‰"""
        for error in errors:
            pos = error.get('pos')
            if pos and error.get('object'):
                # ã‚¯ã‚ªãƒªã‚¢å¼·åº¦ãŒé«˜ã„ã»ã©è¨˜æ†¶ã«æ®‹ã‚Šã‚„ã™ã„
                self.found_objects[pos] = {
                    **error['object'],
                    'memory_strength': qualia_intensity
                }
    
    def mark_visited(self, pos: Tuple[int, int]):
        """è¨ªå•è¨˜éŒ²"""
        self.visited.add(pos)
    
    def remove_object(self, pos: Tuple[int, int]):
        """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå‰Šé™¤ï¼ˆå–å¾—æ™‚ï¼‰"""
        if pos in self.found_objects:
            del self.found_objects[pos]
    
    def get_emotion_label(self, l2_state: Dict) -> str:
        """L2çŠ¶æ…‹ã‹ã‚‰æœ€ã‚‚è¿‘ã„æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™"""
        best_label = None
        best_score = -1
        
        for label, conditions in self.emotion_labels.items():
            score = 0
            match = True
            
            for key, (low, high) in conditions.items():
                if key in ['valence', 'arousal']:
                    value = l2_state.get(key, 0)
                else:
                    value = l2_state.get('qualia', {}).get(key, 0)
                
                if low <= value <= high:
                    score += 1
                else:
                    match = False
                    break
            
            if match and score > best_score:
                best_score = score
                best_label = label
        
        return best_label or 'æ™®é€š'
    
    def get_state(self) -> Dict:
        return {
            'map_size': len(self.internal_map),
            'objects_found': len(self.found_objects),
            'visited_count': len(self.visited),
            'found_objects': dict(self.found_objects)
        }


# ==========================================
# L5: æ„è­˜å±¤ï¼ˆè‡ªèªãƒ»è¨€èªåŒ–ãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
# ==========================================

class L5Consciousness:
    """æ„è­˜ï¼ˆè‡ªèªã€è¨€èªåŒ–ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
    
    def __init__(self, threshold=1.0):
        self.threshold = threshold
        self.is_conscious = False
        self.sync_level = 0.0
        self.state_package = {}
    
    def check_sync(self, l1: L1Body, l2: L2Qualia, l3: L3Prediction, l4: L4Memory) -> bool:
        """å…¨å±¤ã®åŒæœŸã‚’ãƒã‚§ãƒƒã‚¯"""
        # å„å±¤ã®æ´»å‹•åº¦
        l1_activity = (1 - l1.energy) + l1.fatigue  # èº«ä½“çš„è² è·
        l2_activity = abs(l2.valence) + abs(l2.arousal) + sum(l2.qualia.values())
        l3_activity = len(l3.errors) * 0.5
        l4_activity = len(l4.found_objects) * 0.1
        
        self.sync_level = l1_activity + l2_activity + l3_activity + l4_activity
        self.is_conscious = self.sync_level > self.threshold
        
        return self.is_conscious
    
    def self_recognize(self, l1: L1Body, l2: L2Qualia, l3: L3Prediction, l4: L4Memory) -> Dict:
        """L1ã€œL4ã®çŠ¶æ…‹ã‚’è‡ªèªã—ã¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–"""
        l2_state = l2.get_state()
        emotion_label = l4.get_emotion_label(l2_state)
        
        self.state_package = {
            # L1: èº«ä½“
            'body': {
                'energy': l1.energy,
                'fatigue': l1.fatigue,
                'position': l1.position,
                'holding': l1.holding
            },
            # L2: ã‚¯ã‚ªãƒªã‚¢
            'qualia': {
                'valence': l2.valence,
                'arousal': l2.arousal,
                'fear': l2.qualia['fear'],
                'desire': l2.qualia['desire'],
                'urgency': l2.qualia['urgency'],
                'anger': l2.qualia['anger'],
                'sadness': l2.qualia['sadness'],
                'joy': l2.qualia['joy'],
                'disgust': l2.qualia['disgust'],
            },
            # L3: äºˆæ¸¬èª¤å·®
            'prediction': {
                'errors_count': len(l3.errors),
                'recent_errors': l3.errors[-3:] if l3.errors else []
            },
            # L4: è¨˜æ†¶
            'memory': {
                'objects_found': list(l4.found_objects.keys()),
                'visited_count': len(l4.visited)
            },
            # L5: æ„è­˜çŠ¶æ…‹
            'consciousness': {
                'is_conscious': self.is_conscious,
                'sync_level': self.sync_level
            }
        }
        
        return self.state_package
    
    def format_for_llm(self, action: str, decision_details: Dict = None, modulation: Dict = None) -> str:
        """LLMç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        pkg = self.state_package
        
        # å¤‰èª¿å€¤ã‹ã‚‰çµŒé¨“ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¾
        exp_count = modulation.get('experience_count', 0) if modulation else 0
        fear_weight = modulation.get('fear_weight', 1.0) if modulation else 1.0
        safe_pref = modulation.get('safe_preference', 0.0) if modulation else 0.0
        
        prompt = f"""ã‚ãªãŸã¯HIDAã¨ã„ã†æ¢ç´¢ãƒ­ãƒœãƒƒãƒˆã§ã™ã€‚
ä»Šã®çŠ¶æ…‹ã‚’1äººç§°ã§çŸ­ãèªã£ã¦ãã ã•ã„ï¼ˆ2-3æ–‡ã§ï¼‰ã€‚

ã€çµŒé¨“ã€‘
- ã“ã‚Œã¾ã§ã®æ¢ç´¢å›æ•°: {exp_count}å›
- ææ€–ã¸ã®æ„Ÿåº¦: {fear_weight:.2f}ï¼ˆ1.0ãŒæ¨™æº–ã€é«˜ã„ã»ã©æ€–ãŒã‚Šï¼‰
- å®‰å…¨å¿—å‘åº¦: {safe_pref:.2f}ï¼ˆ0.0ãŒæ¨™æº–ã€é«˜ã„ã»ã©å®‰å…¨é‡è¦–ï¼‰

ã€èº«ä½“çŠ¶æ…‹ã€‘
- ã‚¨ãƒãƒ«ã‚®ãƒ¼: {pkg['body']['energy']:.0%}
- ç–²åŠ´åº¦: {pkg['body']['fatigue']:.0%}
- æŒã£ã¦ã„ã‚‹ã‚‚ã®: {pkg['body']['holding'] or 'ãªã—'}

ã€æ„Ÿæƒ…çŠ¶æ…‹ã€‘
- å¿«-ä¸å¿«: {pkg['qualia']['valence']:.2f}
- è¦šé†’åº¦: {pkg['qualia']['arousal']:.2f}
- ææ€–: {pkg['qualia']['fear']:.0%}
- æ¬²æ±‚: {pkg['qualia']['desire']:.0%}
- ç·Šæ€¥åº¦: {pkg['qualia']['urgency']:.0%}
- æ€’ã‚Š: {pkg['qualia']['anger']:.0%}
- æ‚²ã—ã¿: {pkg['qualia']['sadness']:.0%}
- å–œã³: {pkg['qualia']['joy']:.0%}
- å«Œæ‚ª: {pkg['qualia']['disgust']:.0%}

ã€èªè­˜ã€‘
- ç™ºè¦‹ã—ãŸã‚‚ã®: {len(pkg['memory']['objects_found'])}å€‹
- æ¢ç´¢ã—ãŸå ´æ‰€: {pkg['memory']['visited_count']}ç®‡æ‰€

ã€ä»Šã®è¡Œå‹•ã€‘
{action}
"""
        
        if decision_details:
            prompt += f"""
ã€è¡Œå‹•ã®å†…éƒ¨è¨ˆç®—ã€‘
{json.dumps(decision_details, ensure_ascii=False, indent=2)}
"""
        
        prompt += """
æ•°å€¤ã‚’ãã®ã¾ã¾è¨€ã†ã®ã§ã¯ãªãã€æ„Ÿè¦šã¨ã—ã¦è¡¨ç¾ã—ã¦ãã ã•ã„ï¼š"""
        
        return prompt
    
    def get_state(self) -> Dict:
        return {
            'is_conscious': self.is_conscious,
            'sync_level': self.sync_level,
            'state_package': self.state_package
        }


# ==========================================
# LLMé€£æº
# ==========================================

class LLMVerbalizer:
    """LLMè¨€èªåŒ–ï¼ˆollama / Claudeï¼‰"""
    
    def __init__(self, prefer_claude=True):
        self.prefer_claude = prefer_claude
    
    def verbalize(self, prompt: str) -> Tuple[str, str]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨€èªåŒ–"""
        if self.prefer_claude:
            result = self._ask_claude(prompt)
            if result:
                return result, "claude"
        
        result = self._ask_ollama(prompt)
        if result:
            return result, "ollama"
        
        return "(LLMæœªæ¥ç¶š)", "none"
    
    def _ask_ollama(self, prompt: str, model="gemma3:4b") -> Optional[str]:
        try:
            result = subprocess.run(
                ["ollama", "run", model, prompt],
                capture_output=True,
                text=True,
                timeout=60,
                encoding='utf-8',
                errors='replace'
            )
            if result.returncode == 0:
                return result.stdout.strip()
        except:
            pass
        return None
    
    def _ask_claude(self, prompt: str) -> Optional[str]:
        api_key = os.environ.get('ANTHROPIC_API_KEY', '')
        if not api_key:
            return None
        
        data = json.dumps({
            "model": "claude-sonnet-4-20250514",
            "max_tokens": 300,
            "messages": [{"role": "user", "content": prompt}]
        }).encode('utf-8')
        
        req = urllib.request.Request(
            "https://api.anthropic.com/v1/messages",
            data=data,
            headers={
                "Content-Type": "application/json",
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01"
            }
        )
        
        try:
            with urllib.request.urlopen(req, timeout=30) as response:
                result = json.loads(response.read().decode('utf-8'))
                return result['content'][0]['text']
        except:
            return None


# ==========================================
# NPCï¼ˆä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰
# ==========================================

class NPC:
    """ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆé‚ªé­”ã™ã‚‹å­˜åœ¨ï¼‰"""
    
    def __init__(self, name: str, position: List[int]):
        self.name = name
        self.position = position.copy()
        self.holding = None
    
    def step(self, world):
        """ãƒ©ãƒ³ãƒ€ãƒ ã«å‹•ã"""
        directions = [(0, -1), (0, 1), (-1, 0), (1, 0)]
        random.shuffle(directions)
        
        for dx, dy in directions:
            nx, ny = self.position[0] + dx, self.position[1] + dy
            cell = world.get_cell(nx, ny)
            if cell not in ['wall', 'danger']:
                self.position = [nx, ny]
                break
    
    def get_position(self) -> tuple:
        return tuple(self.position)


# ==========================================
# Worldï¼ˆç’°å¢ƒï¼‰
# ==========================================

class World:
    """ã‚°ãƒªãƒƒãƒ‰ãƒ¯ãƒ¼ãƒ«ãƒ‰ç’°å¢ƒ"""
    
    def __init__(self, size=10):
        self.size = size
        self.grid = [['empty' for _ in range(size)] for _ in range(size)]
        self.objects = {}
        self.npcs = []  # ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    
    def add_npc(self, npc: NPC):
        self.npcs.append(npc)
    
    def get_npc_at(self, x, y) -> Optional[NPC]:
        """æŒ‡å®šä½ç½®ã®NPCã‚’å–å¾—"""
        for npc in self.npcs:
            if npc.position[0] == x and npc.position[1] == y:
                return npc
        return None
    
    def step_npcs(self):
        """å…¨NPCã‚’å‹•ã‹ã™"""
        for npc in self.npcs:
            npc.step(self)
    
    def add_wall(self, x, y):
        if 0 <= x < self.size and 0 <= y < self.size:
            self.grid[y][x] = 'wall'
    
    def add_danger(self, x, y):
        if 0 <= x < self.size and 0 <= y < self.size:
            self.grid[y][x] = 'danger'
    
    def add_object(self, name, x, y, color=None, rotten=False):
        self.objects[(x, y)] = {'name': name, 'color': color, 'rotten': rotten}
    
    def get_cell(self, x, y) -> str:
        if 0 <= x < self.size and 0 <= y < self.size:
            return self.grid[y][x]
        return 'wall'
    
    def get_object(self, x, y) -> Optional[Dict]:
        return self.objects.get((x, y))
    
    def remove_object(self, x, y):
        if (x, y) in self.objects:
            del self.objects[(x, y)]
    
    def display(self, hida_pos=None, hida_dir=None):
        dir_chars = {'N': '^', 'S': 'v', 'E': '>', 'W': '<'}
        print("\n=== World ===")
        for y in range(self.size):
            row = ""
            for x in range(self.size):
                if hida_pos and hida_pos[0] == x and hida_pos[1] == y:
                    row += f"[{dir_chars.get(hida_dir, '?')}]"
                elif self.get_npc_at(x, y):
                    row += "[N]"  # NPC
                elif (x, y) in self.objects:
                    obj = self.objects[(x, y)]
                    if obj['color']:
                        row += f"[{obj['color'][0]}]"
                    else:
                        row += "[G]"
                elif self.grid[y][x] == 'wall':
                    row += "[#]"
                elif self.grid[y][x] == 'danger':
                    row += "[!]"
                else:
                    row += "[ ]"
            print(row)


# ==========================================
# HIDAçµ±åˆã‚¯ãƒ©ã‚¹
# ==========================================

class HIDA:
    """5å±¤çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self, color_preference=None):
        self.l1 = L1Body()
        self.l2 = L2Qualia(color_preference)
        self.l3 = L3Prediction()
        self.l4 = L4Memory()
        self.l5 = L5Consciousness(threshold=0.8)
        self.llm = LLMVerbalizer(prefer_claude=True)
        
        self.step_count = 0
        self.action_history = []
    
    def sense(self, world: World):
        """æ„Ÿè¦šå…¥åŠ›ï¼ˆL1 â†’ L3 â†’ L4ï¼‰"""
        # L1: è¦‹ã‚‹
        sense_data = self.l1.look(world)
        
        # L3: äºˆæ¸¬ã¨æ¯”è¼ƒ
        self.l3.predict(self.l4)
        errors = self.l3.compare_with_reality(sense_data, self.l4)
        
        # L4: è¨˜æ†¶æ›´æ–°
        self.l4.update_from_sense(sense_data)
        qualia_intensity = sum(self.l2.qualia.values())
        self.l4.update_from_errors(errors, qualia_intensity)
        
        # L2: ã‚¯ã‚ªãƒªã‚¢ã«äºˆæ¸¬èª¤å·®ã‚’åæ˜ 
        self.l2.update_from_prediction_error(errors)
        
        # å±é™ºã‚¾ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        current_cell = world.get_cell(self.l1.position[0], self.l1.position[1])
        self.l2.update_in_danger_zone(current_cell == 'danger')
        
        return errors
    
    def think(self, world: World) -> Tuple[str, Dict]:
        """æ€è€ƒãƒ»è¡Œå‹•æ±ºå®šï¼ˆL2/L3/L4ã§æ±ºå®šã€L5ã¯é–¢ä¸ã—ãªã„ï¼‰"""
        # ç™ºè¦‹ã—ãŸãƒœãƒ¼ãƒ«
        balls = {}
        for pos, obj in self.l4.found_objects.items():
            if obj.get('name') == 'ball':
                color = obj.get('color', 'unknown')
                dist = abs(pos[0] - self.l1.position[0]) + abs(pos[1] - self.l1.position[1])
                is_danger = self.l4.internal_map.get(pos) == 'danger'
                is_rotten = obj.get('rotten', False)
                balls[color] = {'pos': pos, 'dist': dist, 'is_danger': is_danger, 'is_rotten': is_rotten}
        
        # ã‚´ãƒ¼ãƒ«
        goal_pos = None
        for pos, obj in self.l4.found_objects.items():
            if obj.get('name') == 'goal':
                goal_pos = pos
        
        # è¡Œå‹•æ±ºå®š
        if self.l1.holding and goal_pos:
            return 'go_to_goal', {'target': goal_pos}
        
        if balls and not self.l1.holding:
            # ã‚¹ã‚³ã‚¢è¨ˆç®—
            scores = {}
            details = {}
            q = self.l2.qualia
            mod = self.l2.modulation
            
            for color, info in balls.items():
                pref = self.l2.get_color_desire(color) * 10
                dist_penalty = -info['dist'] * (0.5 + q['urgency'])
                # å±é™ºã‚¾ãƒ¼ãƒ³: fear_weightã§åŸºæœ¬ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚‚å¤‰ã‚ã‚‹
                fear_weight = mod.get('fear_weight', 1.0)
                base_danger = -3 * fear_weight  # åŸºæœ¬ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚‚fear_weightã§å¤‰åŒ–
                fear_penalty = -5 * q['fear'] * fear_weight
                danger_penalty = (base_danger + fear_penalty) if info['is_danger'] else 0
                # å®‰å…¨å¿—å‘: å®‰å…¨ãªã‚‚ã®ã«ãƒœãƒ¼ãƒŠã‚¹ï¼ˆä¿‚æ•°ã‚’ä¸‹ã’ã¦èµ¤ãŒå‹ã¦ã‚‹ã‚ˆã†ã«ï¼‰
                safe_bonus = mod.get('safe_preference', 0.0) * 2 if not info['is_danger'] else 0
                # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ…é‡ã•
                energy_caution = mod.get('energy_caution', 0.0)
                energy_penalty = -5 * (1 - self.l1.energy) * (1 + energy_caution) if info['dist'] > 3 and self.l1.energy < 0.5 else 0
                # ğŸ¤¢ è…ã£ãŸã‚‚ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆdisgustçµŒé¨“ã§å¢—åŠ ï¼‰
                disgust_penalty = -8 * (1 + q['disgust']) if info['is_rotten'] else 0
                
                total = pref + dist_penalty + danger_penalty + safe_bonus + energy_penalty + disgust_penalty
                scores[color] = total
                details[color] = {
                    'preference': pref,
                    'distance_penalty': dist_penalty,
                    'danger_penalty': danger_penalty,
                    'safe_bonus': safe_bonus,
                    'energy_penalty': energy_penalty,
                    'disgust_penalty': disgust_penalty,
                    'total': total
                }
            
            chosen = max(scores, key=scores.get)
            return f'go_to_{chosen}', {'target': balls[chosen]['pos'], 'scores': details, 'chosen': chosen}
        
        return 'explore', {}
    
    def act(self, world: World, action: str, details: Dict) -> bool:
        """è¡Œå‹•å®Ÿè¡Œï¼ˆL1ï¼‰"""
        target = details.get('target')
        
        if target:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«å‘ã‹ã†
            tx, ty = target
            hx, hy = self.l1.position
            
            if hx == tx and hy == ty:
                # åˆ°ç€
                obj = world.get_object(tx, ty)
                if obj and obj.get('name') == 'ball' and not self.l1.holding:
                    self._last_grabbed_color = obj.get('color', 'unknown')  # è‰²ã‚’ä¿å­˜
                    
                    # ğŸ¤¢ è…ã£ãŸãƒœãƒ¼ãƒ«ãªã‚‰disgustä¸Šæ˜‡
                    if obj.get('rotten'):
                        self.l2.qualia['disgust'] = min(1.0, self.l2.qualia['disgust'] + 0.6)
                        self.l2.valence -= 0.4
                        print(f"    ğŸ¤¢ è…ã£ã¦ã‚‹ï¼ disgust={self.l2.qualia['disgust']:.2f}")
                    
                    self.l1.grab(obj)
                    world.remove_object(tx, ty)
                    self.l4.remove_object((tx, ty))
                    return True
                elif obj and obj.get('name') == 'goal' and self.l1.holding:
                    self.l1.release()
                    return True
            else:
                # ç§»å‹•
                dx = 1 if tx > hx else (-1 if tx < hx else 0)
                dy = 1 if ty > hy else (-1 if ty < hy else 0)
                
                # æ–¹å‘èª¿æ•´
                if dx > 0:
                    target_dir = 'E'
                elif dx < 0:
                    target_dir = 'W'
                elif dy > 0:
                    target_dir = 'S'
                else:
                    target_dir = 'N'
                
                if self.l1.direction != target_dir:
                    # å›è»¢
                    dirs = ['N', 'E', 'S', 'W']
                    ci = dirs.index(self.l1.direction)
                    ti = dirs.index(target_dir)
                    diff = (ti - ci) % 4
                    if diff == 1:
                        self.l1.turn_right()
                    else:
                        self.l1.turn_left()
                else:
                    # NPCãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯
                    dx, dy = {'N': (0, -1), 'S': (0, 1), 'E': (1, 0), 'W': (-1, 0)}[self.l1.direction]
                    next_pos = (self.l1.position[0] + dx, self.l1.position[1] + dy)
                    npc = world.get_npc_at(next_pos[0], next_pos[1])
                    if npc:
                        # ğŸ˜  é‚ªé­”ã•ã‚ŒãŸï¼
                        self.l2.qualia['anger'] = min(1.0, self.l2.qualia['anger'] + 0.3)
                        self.l2.arousal += 0.2
                        print(f"    ğŸ˜  {npc.name}ã«é‚ªé­”ã•ã‚ŒãŸï¼ anger={self.l2.qualia['anger']:.2f}")
                    else:
                        self.l1.move_forward(world)
                        # å±é™ºã‚¾ãƒ¼ãƒ³ãƒ€ãƒ¡ãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯ï¼ˆ33%ï¼‰
                        self._check_danger_damage(world)
        else:
            # æ¢ç´¢ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰
            action = random.choice(['forward', 'left', 'right'])
            if action == 'forward':
                self.l1.move_forward(world)
                self._check_danger_damage(world)
            elif action == 'left':
                self.l1.turn_left()
            else:
                self.l1.turn_right()
        
        return False
    
    def _check_danger_damage(self, world: World):
        """å±é™ºã‚¾ãƒ¼ãƒ³ã§2ç¨®é¡ã®ãƒ€ãƒ¡ãƒ¼ã‚¸åˆ¤å®š"""
        x, y = self.l1.position
        if world.get_cell(x, y) == 'danger':
            
            # ç—›ã¿ï¼ˆ33%ï¼‰â†’ ææ€–ãƒ»æ€’ã‚Šä¸Šæ˜‡
            if random.random() < 0.33:
                self.l2.qualia['fear'] = min(1.0, self.l2.qualia['fear'] + 0.4)
                self.l2.qualia['anger'] = min(1.0, self.l2.qualia['anger'] + 0.2)  # ç—›ã„ã¨æ€’ã‚‹
                self.l2.valence -= 0.3
                self.l2.arousal += 0.3
                
                self.l4.remember_consciously(
                    "danger_pain",
                    self.l1.get_state(),
                    self.l2.get_state()
                )
                print(f"    âš¡ ç—›ã„ï¼ fear={self.l2.qualia['fear']:.2f} anger={self.l2.qualia['anger']:.2f}")
            
            # ç–²åŠ´ï¼ˆ33%ï¼‰â†’ ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¸›å°‘ãƒ»æ‚²ã—ã¿ä¸Šæ˜‡
            if random.random() < 0.33:
                damage = 0.15
                self.l1.energy = max(0, self.l1.energy - damage)
                self.l2.qualia['sadness'] = min(1.0, self.l2.qualia['sadness'] + 0.15)  # ç–²ã‚Œã‚‹ã¨æ‚²ã—ããªã‚‹
                
                self.l4.remember_consciously(
                    "danger_fatigue",
                    self.l1.get_state(),
                    self.l2.get_state()
                )
                print(f"    ğŸ’¦ ç–²ã‚ŒãŸï¼ E={self.l1.energy:.2f} sadness={self.l2.qualia['sadness']:.2f}")
    
    def reflect(self, action: str, details: Dict) -> Optional[str]:
        """å†…çœãƒ»è¨€èªåŒ–ï¼ˆL5 â†’ LLMï¼‰"""
        # L5: åŒæœŸãƒã‚§ãƒƒã‚¯
        is_conscious = self.l5.check_sync(self.l1, self.l2, self.l3, self.l4)
        
        if not is_conscious:
            return None
        
        # L5: è‡ªèª
        self.l5.self_recognize(self.l1, self.l2, self.l3, self.l4)
        
        # L4: æ„è­˜çš„ã«è¨˜æ†¶ã™ã‚‹
        self.l4.remember_consciously(
            action, 
            self.l1.get_state(), 
            self.l2.get_state()
        )
        
        # L5: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆå¤‰èª¿å€¤ã‚’æ•°å€¤ã¨ã—ã¦æ¸¡ã™ï¼‰
        modulation = self.l4.get_modulation()
        prompt = self.l5.format_for_llm(action, details.get('scores'), modulation)
        
        # LLM: è¨€èªåŒ–
        response, llm_type = self.llm.verbalize(prompt)
        
        return f"({llm_type}) {response}"
    
    def step(self, world: World, verbose=True) -> Dict:
        """1ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ"""
        self.step_count += 1
        
        # å¤‰èª¿å€¤ã‚’L2ã«é©ç”¨
        self.l2.apply_modulation(self.l4.get_modulation())
        
        # L2: èº«ä½“çŠ¶æ…‹ã‹ã‚‰ã‚¯ã‚ªãƒªã‚¢æ›´æ–°
        self.l2.update_from_body(self.l1.get_state())
        
        # æ„Ÿè¦šå…¥åŠ›
        errors = self.sense(world)
        
        # æ€è€ƒ
        action, details = self.think(world)
        
        # è¡Œå‹•
        goal_reached = self.act(world, action, details)
        
        # è¨ªå•è¨˜éŒ²
        self.l4.mark_visited(tuple(self.l1.position))
        
        # ã‚¯ã‚ªãƒªã‚¢æ¸›è¡°
        self.l2.decay_qualia()
        
        # å†…çœï¼ˆæ„è­˜çš„ãªã‚‰ï¼‰
        reflection = None
        if verbose and self.step_count % 5 == 0:
            reflection = self.reflect(action, details)
        
        # ã‚´ãƒ¼ãƒ«åˆ°é”æ™‚ã«è¨˜æ†¶ï¼ˆreleaseã™ã‚‹å‰ã«è‰²ã‚’å–å¾—ï¼‰
        if goal_reached:
            grabbed_color = 'unknown'
            # holdingãŒã‚ã‚‹å ´åˆï¼ˆactã§releaseã™ã‚‹å‰ã«ä¿å­˜ã•ã‚ŒãŸï¼‰
            if hasattr(self, '_last_grabbed_color'):
                grabbed_color = self._last_grabbed_color
            
            # ğŸ‰ joyä¸Šæ˜‡ï¼ˆç›®æ¨™é”æˆï¼‰
            self.l2.qualia['joy'] = min(1.0, self.l2.qualia['joy'] + 0.5)
            # å¥½ããªè‰²ã ã£ãŸã‚‰ã•ã‚‰ã«joy
            color_pref = self.l2.color_preference.get(grabbed_color, 0.5)
            if color_pref > 0.7:
                self.l2.qualia['joy'] = min(1.0, self.l2.qualia['joy'] + 0.3)
            self.l2.valence += 0.3  # å¿«æ–¹å‘ã¸
            
            self.l4.remember_consciously(
                f"goal_reached_with_{grabbed_color}",
                self.l1.get_state(),
                self.l2.get_state(),
                is_session_end=True
            )
        
        result = {
            'step': self.step_count,
            'action': action,
            'position': self.l1.position.copy(),
            'energy': self.l1.energy,
            'holding': self.l1.holding,
            'conscious': self.l5.is_conscious,
            'goal_reached': goal_reached,
            'reflection': reflection
        }
        
        if verbose:
            q = self.l2.qualia
            print(f"\n  Step {self.step_count}: {action}")
            print(f"    E={self.l1.energy:.2f} F={q['fear']:.2f} D={q['desire']:.2f} U={q['urgency']:.2f}")
            if details.get('scores'):
                print(f"    Scores: {[(c, f'{d['total']:.1f}') for c, d in details['scores'].items()]}")
            if reflection:
                print(f"    ğŸ’­ {reflection}")
        
        # NPCã‚‚å‹•ã‹ã™
        world.step_npcs()
        
        return result


# ==========================================
# ãƒ†ã‚¹ãƒˆ
# ==========================================

def create_test_world():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ¯ãƒ¼ãƒ«ãƒ‰"""
    world = World(size=10)
    
    # å¤–å£
    for i in range(10):
        world.add_wall(i, 0)
        world.add_wall(i, 9)
        world.add_wall(0, i)
        world.add_wall(9, i)
    
    # å±é™ºã‚¾ãƒ¼ãƒ³
    for x in range(5, 8):
        for y in range(2, 5):
            world.add_danger(x, y)
    
    # ãƒœãƒ¼ãƒ«
    world.add_object("ball", 6, 3, color="red")    # å±é™ºã‚¾ãƒ¼ãƒ³
    world.add_object("ball", 2, 4, color="blue")   # å®‰å…¨
    world.add_object("ball", 2, 7, color="green")  # å®‰å…¨
    world.add_object("ball", 4, 6, color="yellow", rotten=True)  # è…ã£ã¦ã‚‹ï¼ˆè¿‘ã„ï¼‰
    
    # ã‚´ãƒ¼ãƒ«
    world.add_object("goal", 7, 7)
    
    # NPCï¼ˆé‚ªé­”ã™ã‚‹å­˜åœ¨ï¼‰
    npc = NPC("ãƒœãƒ–", [4, 5])
    world.add_npc(npc)
    
    return world


def run_test(color_pref, initial_energy=1.0, max_steps=50):
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    world = create_test_world()
    hida = HIDA(color_preference=color_pref)
    hida.l1.position = [3, 6]
    hida.l1.direction = 'N'
    hida.l1.energy = initial_energy
    
    # å¤‰èª¿å€¤è¡¨ç¤º
    mod = hida.l4.get_modulation()
    personality = hida.l4.get_personality_description()
    print(f"  æ€§æ ¼: {personality}")
    print(f"  å¤‰èª¿: fear_weight={mod['fear_weight']:.2f}, safe_pref={mod['safe_preference']:.2f}, exp={mod['experience_count']}")
    
    # ãƒœãƒ¼ãƒ«ã‚’æœ€åˆã‹ã‚‰ç™ºè¦‹æ¸ˆã¿ã«ã™ã‚‹
    hida.l4.found_objects[(6, 3)] = {'name': 'ball', 'color': 'red'}
    hida.l4.found_objects[(2, 4)] = {'name': 'ball', 'color': 'blue'}
    hida.l4.found_objects[(2, 7)] = {'name': 'ball', 'color': 'green'}
    hida.l4.found_objects[(4, 6)] = {'name': 'ball', 'color': 'yellow', 'rotten': True}
    hida.l4.found_objects[(7, 7)] = {'name': 'goal', 'color': None}
    
    # ãƒãƒƒãƒ—ã‚‚ä¸ãˆã‚‹
    for x in range(1, 9):
        for y in range(1, 9):
            if world.get_cell(x, y) == 'danger':
                hida.l4.internal_map[(x, y)] = 'danger'
            else:
                hida.l4.internal_map[(x, y)] = 'empty'
    
    print(f"\n{'='*60}")
    print(f"è‰²å¥½ã¿: {color_pref}")
    print(f"åˆæœŸã‚¨ãƒãƒ«ã‚®ãƒ¼: {initial_energy}")
    print(f"  èµ¤: å±é™ºã‚¾ãƒ¼ãƒ³å†…")
    print(f"  é’: å®‰å…¨ã€ã‚„ã‚„é ã„")
    print(f"  ç·‘: å®‰å…¨ã€è¿‘ã„")
    world.display(hida.l1.position, hida.l1.direction)
    
    for _ in range(max_steps):
        result = hida.step(world)
        
        if result['goal_reached']:
            print(f"\nğŸ† ã‚´ãƒ¼ãƒ«åˆ°é”ï¼")
            break
        
        if result['holding'] and 'go_to' in result['action']:
            # ãƒœãƒ¼ãƒ«å–å¾—
            pass
        
        if hida.l1.energy <= 0:
            print(f"\nğŸ’€ ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ‡ã‚Œ")
            break
    
    # æœ€çµ‚å†…çœ
    print(f"\n=== æœ€çµ‚å†…çœ ===")
    final_action = f"çµæœ: {result['holding']}ã‚’å–å¾—" if result['holding'] else "æ¢ç´¢ä¸­"
    reflection = hida.reflect(final_action, {})
    if reflection:
        print(f"ğŸ’­ {reflection}")
    
    return hida


if __name__ == "__main__":
    import sys
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    if len(sys.argv) > 1 and sys.argv[1] == "loop":
        # ãƒ«ãƒ¼ãƒ—ãƒ¢ãƒ¼ãƒ‰ï¼šä½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã§5å›å®Ÿè¡Œã—ã¦ä¿¡å¿µå½¢æˆã‚’è¦‹ã‚‹
        print("=== ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼5å›ï¼ˆæ…é‡ã«ãªã‚‹ï¼‰===")
        for i in range(5):
            print(f"\n{'#'*60}")
            print(f"# ã‚»ãƒƒã‚·ãƒ§ãƒ³ {i+1}")
            print(f"{'#'*60}")
            run_test({'red': 1.0, 'blue': 0.3, 'green': 0.3}, initial_energy=0.3, max_steps=30)
    
    elif len(sys.argv) > 1 and sys.argv[1] == "loop_high":
        # é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ«ãƒ¼ãƒ—ï¼šå†’é™ºçš„ã«ãªã‚‹
        print("=== é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼5å›ï¼ˆå†’é™ºçš„ã«ãªã‚‹ï¼‰===")
        for i in range(5):
            print(f"\n{'#'*60}")
            print(f"# ã‚»ãƒƒã‚·ãƒ§ãƒ³ {i+1}")
            print(f"{'#'*60}")
            run_test({'red': 1.0, 'blue': 0.3, 'green': 0.3}, initial_energy=1.0, max_steps=30)
    
    elif len(sys.argv) > 1 and sys.argv[1] == "reset":
        # ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰
        import os
        for f in ["hida_ltm.json", "hida_modulation.json"]:
            if os.path.exists(f):
                os.remove(f)
                print(f"å‰Šé™¤: {f}")
        print("è¨˜æ†¶ã¨å¤‰èª¿å€¤ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    else:
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
        print("=== HIDAçµ±åˆç‰ˆãƒ†ã‚¹ãƒˆ ===")
        print("ï¼ˆloop: ä½E5å›, loop_high: é«˜E5å›, reset: ãƒªã‚»ãƒƒãƒˆï¼‰")
        
        # ãƒ†ã‚¹ãƒˆ1: èµ¤å¥½ãã€é€šå¸¸ã‚¨ãƒãƒ«ã‚®ãƒ¼
        print("\nã€ãƒ†ã‚¹ãƒˆ1ã€‘èµ¤å¥½ãã€é€šå¸¸ã‚¨ãƒãƒ«ã‚®ãƒ¼")
        run_test({'red': 1.0, 'blue': 0.3, 'green': 0.3}, initial_energy=1.0)
        
        # ãƒ†ã‚¹ãƒˆ2: èµ¤å¥½ãã€ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼
        print("\nã€ãƒ†ã‚¹ãƒˆ2ã€‘èµ¤å¥½ãã€ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼")
        run_test({'red': 1.0, 'blue': 0.3, 'green': 0.3}, initial_energy=0.3)
