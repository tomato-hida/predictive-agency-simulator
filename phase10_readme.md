# Phase 10: Language Inheritance Test

## 概要

「言語は継承（教示）が必要」を検証する実験。

## 仮説

「LLM は数値からラベル付けできない」のではなく
「ラベル付けには継承（教示）が必要」
= 人間と同じ（親から言葉を教わる）

## 実験結果

### 辞書なし（1回教えて、後は数値だけ）

```
正答率: 0%
```

LLM は辞書を「覚えていなかった」。

### 辞書を毎回渡す

```
正答率: 64.3%
```

辞書があれば、LLM は数値からラベル付けできた。

### 成功例

```
テスト 3: 4/4 完璧
  qv=+0.50 → 「心地よい」 ✓
  em=+0.30 → 「やや安心」 ✓

テスト 5: 4/4 完璧
  qv=0.00 → 「普通」 ✓
  em=0.00 → 「落ち着いている」 ✓
```

### 失敗例（境界ケース）

```
テスト 6:
  qv=+0.35 → 期待「心地よい」、LLM「普通」
  → 境界（0.3）付近で迷っている
```

## Ollama の制約について

本実験は Ollama（ローカル LLM）を使用している。

### 制約

1. **コンテキストが毎回リセットされる**
   - 1回目で辞書を教えても、2回目のリクエストでは忘れている
   - API の仕様上、会話の継続が難しい

2. **モデルサイズの限界**
   - Gemma 4B は小さいモデル
   - 指示追従能力に限界がある

### 対応

- 辞書を毎回プロンプトに含める方式で実験
- これは人間で言えば「教科書を見ながら答える」状態
- 「記憶」ではなく「参照」による言語継承

### より良い環境

- 会話を継続できる API（Claude API、GPT API など）
- より大きなモデル（Gemma 12B、27B など）
- Fine-tuning による辞書の内在化

## 結論

### 実証されたこと

辞書（範囲 → ラベルの対応）を渡せば、LLM は数値からラベル付けできる。

```
-0.90 → 「痛い」
+0.50 → 「心地よい」
+0.00 → 「普通」
```

### 概念の正しさ

**「言語は継承が必要」という方向性は正しい。**

- 辞書なし: 0%
- 辞書あり: 64.3%

この差が示しているのは：
- LLM は数値から「意味を発明」できない
- しかし「意味を教えてもらえば」適用できる
- これは人間の言語獲得と同じ構造

人間も親から「痛い」「暖かい」という言葉を教わる。
数値（神経信号）だけでは意味は生まれない。
言葉（ラベル）を継承して初めてクオリアが完成する。

### 残された課題

1. 境界ケースの精度向上（ただし下記参照）
2. 会話継続可能な環境での再検証
3. 辞書を「記憶」として内在化する方法

### 境界ケースについての洞察

LLM が境界で「迷う」のは、実は人間と同じ現象かもしれない。

**コードの発想（離散的）**
```
-0.3 〜 +0.3 = 普通
+0.3 〜 +0.7 = 心地よい
→ 境界は「どっちか」
```

**人間の実感（連続的）**
```
痛痒い
ダル痛い
甘酸っぱい
→ 境界は「両方」
```

クオリアは離散的に分かれているわけではない。
「痛い」と「痒い」は別々に存在するのではなく、グラデーションで繋がっている。
境界付近では複数のクオリアが重なって感じられる。

**設計への示唆**

現在：1つの値 → 1つのラベル
改善案：1つの値 → 複数のラベルを重みつきで返す

```
qv = -0.35 → 「不快 60%、普通 40%」
qv = +0.32 → 「普通 55%、心地よい 45%」
```

LLM が境界で迷うのは「バグ」ではなく「人間らしさ」の可能性がある。

## 実行方法

```bash
# Ollama が起動していることを確認
python phase10_language_inheritance.py
```

## 技術的注意

- Ollama のコンテキストは毎回リセットされる
- 辞書は毎回プロンプトに含める必要がある
- 結果は実行ごとに若干変動する（LLM の性質）
