# 飛騨アーキテクチャ Phase 16

5層意識モデルに基づくロボット制御システム

## 概要

飛騨は「人間の内面運動理論（5層モデル）」を実装したロボットアーキテクチャです。
言葉とプリミティブ（基本動作）を紐づけて学習し、予測誤差に基づいて行動します。

## 特徴

- **1ファイルで動作**: `hida_phase16.py` だけで完結
- **依存なし**: Python標準ライブラリのみ
- **94個のDNA知識**: 最初から多くの言葉を理解
- **意図と対象の分離**: 「赤いボールを持ってきて」を意図と対象に分解
- **学習機能**: 知らない言葉は質問して覚える
- **永続記憶**: 学習内容はJSONに保存、再起動後も有効
- **スレッド安全**: Lock で競合を防止

## 5層構造

| 層 | 名前 | 役割 |
|---|---|---|
| L1 | 身体層 | プリミティブ（基本動作）の実行 |
| L2 | クオリア層 | センサー入力にラベルと評価値を付与 |
| L3 | 構造化層 | 予測と誤差の計算、L4と連携 |
| L4 | 記憶層 | 言葉→プリミティブ、意図→行動、対象→特徴 |
| L5 | 意識層 | 全層同期、70%ルールで過負荷保護 |

## 使い方

### 起動

```bash
python hida_phase16.py
```

### 基本操作

```
あなた: 飛騨、前に進め
  [L3] 予測: 「前に進め」→ ['move_forward'] (確信度: 0.9)
  [L1] move_forward → 成功

あなた: 飛騨、うなずいて
  [L3] 予測: 「うなずいて」→ ['neck_down', 'neck_up', ...] (確信度: 0.9)
  [L1] neck_down → 成功
  [L1] neck_up → 成功
```

### 新しい言葉を教える

```
あなた: 飛騨、シェイクして
  [L3] 予測不能: 「シェイクして」は知らない言葉
  → 【質問】何をすればいいですか？

あなた: right.hand_close, right.shoulder_up, waist_left, waist_right
  [テスト] ['right.hand_close', 'right.shoulder_up', 'waist_left', 'waist_right']
  [L1] right.hand_close → 成功
  ...
  → 学習完了！「シェイクして」を覚えました
```

### 教えた言葉を忘れさせる

```
あなた: 飛騨、シェイクを忘れて
  → 「シェイク」を忘れました
```

※ DNA知識（生まれつきの知識）は忘れられません

### 学習をキャンセル

質問中に「やめ」「キャンセル」と入力すればキャンセルできます。

```
あなた: 飛騨、ホゲホゲ
  → 【質問】何をすればいいですか？

あなた: やめ
  → キャンセルしました
```

### コマンド

- `q`: 終了
- `状態`: 5層の状態を表示

### 力加減（修飾語）

言葉に修飾語をつけると、動作の速度・力・角度を調整できます。

```
あなた: 飛騨、ゆっくり前に進め
  [修飾語] 「ゆっくり」→ 倍率 0.3x
  [L1] move_forward (x0.3) → 成功

あなた: 飛騨、思いっきり前に進め
  [修飾語] 「思いっきり」→ 倍率 3.0x
  [L1] move_forward (x3.0) → 成功
```

### 意図と対象の分離

「〇〇を△△して」という命令を、意図（動詞）と対象（名詞）に分解します。

```
あなた: 飛騨、赤いボールを持ってきて
  [L4] 意図: 「持ってきて」, 対象: 「赤いボール」
  [L4] 対象の特徴: {'color': 'red', 'shape': 'sphere'}
  [探索] 「赤いボール」を探しています...
  [探索] 「赤いボール」を発見！
  [移動] 「赤いボール」に接近中...
  [移動] 「赤いボール」に到達
  [L1] right.hand_open → 成功
  [L1] right.hand_close → 成功
  ...
```

これにより「青いボールを持ってきて」も再学習なしで動作します（意図は同じ、対象だけ変わる）。

#### 登録済みの意図

| 意図 | 動作 |
|------|------|
| 持ってきて | 探索→接近→掴む→戻る→離す |
| 探して | 対象を探索 |
| 見つけて | 対象を探索 |
| 取って | 接近→掴む |
| 置いて | 下げる→離す |
| 渡して | 接近→上げる→離す |
| 見て | 対象を見る |

#### 登録済みの対象

赤いボール、青いボール、緑のボール、ボール、赤い箱、青い箱、箱、人、壁

#### 修飾語一覧

| 修飾語 | 倍率 | 用途 |
|--------|------|------|
| ゆっくり | 0.3x | 遅く・弱く |
| そっと | 0.3x | 遅く・弱く |
| 軽く | 0.3x | 遅く・弱く |
| 少し | 0.5x | やや遅く |
| ちょっと | 0.5x | やや遅く |
| やや | 0.7x | やや遅く |
| もっと | 1.5x | やや速く |
| 速く / 早く | 2.0x | 速く・強く |
| 強く | 2.0x | 速く・強く |
| 大きく | 2.0x | 速く・強く |
| すごく | 2.0x | 速く・強く |
| かなり | 2.0x | 速く・強く |
| 思いっきり | 3.0x | 最大 |
| 全力で | 3.0x | 最大 |

## 学習方法

### 1. 人が教える

対話で知らない言葉が出たら質問される。プリミティブをカンマ区切りで入力すれば学習。

### 2. AI（Claude等）に教えさせる

DNA_KNOWLEDGE に追加すれば、起動時から使える。

```python
DNA_KNOWLEDGE = {
    "新しい言葉": ["primitive1", "primitive2", ...],
    ...
}
```

AIは言葉の意味を知っているので、プリミティブの組み合わせに変換できる。
人間が教える手間を大幅に削減。

## プリミティブ一覧

### 移動系
- `move_forward`: 前進
- `move_back`: 後退
- `turn_left`: 左回転
- `turn_right`: 右回転
- `stop`: 停止

### 腰
- `waist_left`: 腰を左に回す
- `waist_right`: 腰を右に回す

### 首
- `neck_left`: 首を左に向ける
- `neck_right`: 首を右に向ける
- `neck_up`: 上を向く
- `neck_down`: 下を向く

### 腕（right. または left. を前につける）
- `shoulder_up`: 肩を上げる
- `shoulder_down`: 肩を下げる
- `elbow_bend`: 肘を曲げる
- `elbow_straight`: 肘を伸ばす
- `wrist_up`: 手首を上げる
- `wrist_down`: 手首を下げる
- `wrist_rotate`: 手首を回す
- `hand_open`: 手を開く
- `hand_close`: 手を握る

### 感覚
- `look`: 見る
- `listen`: 聞く

### 出力
- `say`: 話す（未実装）

## DNA知識（94個）

### 基本動作
前に進め、後退、下がれ、左を向け、右を向け、止まれ、ストップ...

### コミュニケーション
うなずいて、はい、OK、首を振って、いいえ、挨拶して、こんにちは、バイバイ、手を振って...

### 感情表現
喜んで、悲しんで、驚いて、考えて、お手上げ、降参...

### 感覚動作
見て、聞いて、上を見て、下を見て、周りを見て、キョロキョロして、探して、見回して...

### 把持動作
取って、つかんで、握って、離して、持ち上げて、置いて、渡して、受け取って...

### 複合動作
踊って、ダンス、ストレッチ、体操して、回れ、一周して、近づいて、離れて...

## ファイル

- `hida_phase16.py`: メインプログラム（約1500行）
- `hida_memory.json`: 学習した記憶（自動生成）

## 理論的背景

このシステムは「人間の内面運動理論（5層モデル）」に基づいています。

- 予測誤差が大きい → 意識ON → 学習
- 予測誤差が小さい → 意識OFF → 自動処理
- 意識の持続率は70%以下（過負荷保護）

## 今後の予定（実機接続）

L1（身体層）にモーター制御コードを追加すれば、実際のロボットが動くはず。
L2〜L5 のロジックはそのまま使える。

### 接続方法の候補

| 方法 | 説明 |
|------|------|
| Raspberry Pi + Python | GPIOでモーター制御。Pythonそのまま動く |
| Arduino | シリアル通信で指令送信。Arduino側でPWM制御 |
| ROS | トピックにメッセージ送信。本格的なロボット向け |
| PyBullet / Gazebo | シミュレーション環境。テスト用 |

### 実装イメージ

```python
# 現在（シミュレーション）
def move_forward(self, distance=0.1):
    self.position[0] += distance
    return PrimitiveResult.SUCCESS

# 実機（例: Raspberry Pi）
def move_forward(self, distance=0.1):
    self.position[0] += distance
    
    # モーター制御を追加
    motor.set_speed(100 * distance)
    time.sleep(0.5)
    motor.stop()
    
    return PrimitiveResult.SUCCESS
```

※ まだ実機では試していないため、実際に動くかは未検証

## ライセンス

MIT License
