# Phase 9: Validation Tests

## 概要

GPT の批判に基づく検証テスト。

「LLM が解釈済みラベルを要約しているだけでは？」
「HIDA の状態が本当に出力を支配しているのか？」

3つのテストで検証した。

## 3つのテスト

### TEST 1: MASK（ラベルを隠す）

「心地よい」「ぼんやり」等の解釈済みラベルを削除。
数値と ID だけを LLM に渡す。

**目的**：ラベルがないと出力が崩れるか？

**結果**：
```
ラベルあり → Serene（穏やか）
数値のみ   → Empty, Neutral, Unsettled
```

**評価**：✗ ラベル依存が確認された

LLM は数値だけでは意味を取れない。
「心地よい」と教えてもらって初めて適切な出力ができる。

### TEST 2: SHUFFLE（状態を入れ替え）

刺激と状態をランダムに入れ替える。
整合性が落ちるか確認。

**目的**：状態と出力に相関があるか？

**結果**：
```
正常系      → Dissonance, Disappointment, Melancholy
シャッフル系 → Dissonance, Disappointment, Melancholy
```

**評価**：△ 差が小さい

数値だけだと LLM が適当に答えている可能性。

### TEST 3: GATE（意識ON/OFFで出力形式を制御）

意識 OFF → 単語のみ
意識 ON → 2文以上

**目的**：意識フラグが出力形式を支配するか？

**結果**：
```
意識 OFF → 単語数: 1
意識 ON  → 単語数: 89
```

**評価**：✓ 意識フラグは出力形式を支配している

## 正直な総合評価

| テスト | 結果 | 意味 |
|--------|------|------|
| MASK | ✗ | ラベル依存あり。数値だけでは機能しない |
| SHUFFLE | △ | 状態との相関は弱い |
| GATE | ✓ | 意識フラグは出力を支配している |

### GPT の批判への回答

「LLM が解釈済みラベルを要約しているだけ」
→ **半分正しい**（MASK で確認）

「HIDA の状態が出力を支配している」
→ **部分的に正しい**（GATE で確認）

### 現状の限界

- クオリアの「意味」は、まだ人間が言葉でラベル付けしている
- LLM は数値パターンから意味を読み取れていない
- 意識フラグによる出力制御は機能している

### 次の課題

1. ラベルなしで意味を伝える方法
   - パターンの学習
   - 複数回の経験からの抽象化

2. 状態と出力の相関を強化
   - より明確な状態差を作る
   - 出力の評価基準を明確化

## 実行方法

```bash
# Ollama が起動していることを確認
python phase9_validation_tests.py
```

## 結論

過大評価せず、過小評価せず。
弱い部分は弱いと認め、効いている部分は効いていると報告する。
これが誠実な研究。
